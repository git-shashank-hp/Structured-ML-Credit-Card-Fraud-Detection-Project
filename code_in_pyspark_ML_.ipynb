{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOX7Q8bBBZnnyxvdXCZUJn7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/git-shashank-hp/Structured-ML-Credit-Card-Fraud-Detection-Project/blob/main/code_in_pyspark_ML_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZJhLv0_mlk23"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import feature\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Spark ML Example\") \\\n",
        "    .getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBfulXWYlmGq",
        "outputId": "5dd5782f-7059-46f1-a918-78ad1b4b02e0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/gdrive/MyDrive/Colab Notebooks/CCDP/fraudTrain.csv'"
      ],
      "metadata": {
        "id": "TY8HZ5xIluzM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading CSV data into a Spark DataFrame\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Show first few rows of data\n",
        "df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvHqUM5pl1q5",
        "outputId": "9418f161-5bec-44a0-c26e-ac024e56b986"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------------------+----------------+--------------------+-------------+------+---------+-------+------+--------------------+--------------+-----+-----+-------+---------+--------+--------------------+----------+--------------------+----------+------------------+-----------+--------+\n",
            "|_c0|trans_date_trans_time|          cc_num|            merchant|     category|   amt|    first|   last|gender|              street|          city|state|  zip|    lat|     long|city_pop|                 job|       dob|           trans_num| unix_time|         merch_lat| merch_long|is_fraud|\n",
            "+---+---------------------+----------------+--------------------+-------------+------+---------+-------+------+--------------------+--------------+-----+-----+-------+---------+--------+--------------------+----------+--------------------+----------+------------------+-----------+--------+\n",
            "|  0|  2019-01-01 00:00:18|2703186189652095|fraud_Rippin, Kub...|     misc_net|  4.97| Jennifer|  Banks|     F|      561 Perry Cove|Moravian Falls|   NC|28654|36.0788| -81.1781|    3495|Psychologist, cou...|1988-03-09|0b242abb623afc578...|1325376018|         36.011293| -82.048315|       0|\n",
            "|  1|  2019-01-01 00:00:44|    630423337322|fraud_Heller, Gut...|  grocery_pos|107.23|Stephanie|   Gill|     F|43039 Riley Green...|        Orient|   WA|99160|48.8878|-118.2105|     149|Special education...|1978-06-21|1f76529f857473494...|1325376044|49.159046999999994|-118.186462|       0|\n",
            "|  2|  2019-01-01 00:00:51|  38859492057661|fraud_Lind-Buckridge|entertainment|220.11|   Edward|Sanchez|     M|594 White Dale Su...|    Malad City|   ID|83252|42.1808| -112.262|    4154|Nature conservati...|1962-01-19|a1a22d70485983eac...|1325376051|         43.150704|-112.154481|       0|\n",
            "|  3|  2019-01-01 00:01:16|3534093764340240|fraud_Kutch, Herm...|gas_transport|  45.0|   Jeremy|  White|     M|9443 Cynthia Cour...|       Boulder|   MT|59632|46.2306|-112.1138|    1939|     Patent attorney|1967-01-12|6b849c168bdad6f86...|1325376076|         47.034331|-112.561071|       0|\n",
            "|  4|  2019-01-01 00:03:06| 375534208663984| fraud_Keeling-Crist|     misc_pos| 41.96|    Tyler| Garcia|     M|    408 Bradley Rest|      Doe Hill|   VA|24433|38.4207| -79.4629|      99|Dance movement ps...|1986-03-28|a41d7549acf907893...|1325376186|         38.674999| -78.632459|       0|\n",
            "+---+---------------------+----------------+--------------------+-------------+------+---------+-------+------+--------------------+--------------+-----+-----+-------+---------+--------+--------------------+----------+--------------------+----------+------------------+-----------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print schema to see column names and types\n",
        "df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8Zvj-MGl9fd",
        "outputId": "7a26b85f-4e6c-4f0f-8f3f-b5a99949231f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- trans_date_trans_time: timestamp (nullable = true)\n",
            " |-- cc_num: long (nullable = true)\n",
            " |-- merchant: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- amt: double (nullable = true)\n",
            " |-- first: string (nullable = true)\n",
            " |-- last: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- street: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- zip: integer (nullable = true)\n",
            " |-- lat: double (nullable = true)\n",
            " |-- long: double (nullable = true)\n",
            " |-- city_pop: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- dob: date (nullable = true)\n",
            " |-- trans_num: string (nullable = true)\n",
            " |-- unix_time: integer (nullable = true)\n",
            " |-- merch_lat: double (nullable = true)\n",
            " |-- merch_long: double (nullable = true)\n",
            " |-- is_fraud: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row_count = df.count()\n",
        "print(f\"Number of rows: {row_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ktoZeLqmPTI",
        "outputId": "88fad8ff-807b-4d3b-f343-75c3a58a253f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows: 1296675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZNE8uxBmgA2",
        "outputId": "c6d61461-c940-468a-9766-d05919d30ec4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"HaversineExample\").getOrCreate()\n",
        "\n",
        "# Haversine formula function to calculate distance between two latitudes and longitudes (in kilometers)\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    # Radius of the Earth in kilometers\n",
        "    R = 6371.0\n",
        "\n",
        "    # Convert degrees to radians\n",
        "    lat1_rad = math.radians(lat1)\n",
        "    lon1_rad = math.radians(lon1)\n",
        "    lat2_rad = math.radians(lat2)\n",
        "    lon2_rad = math.radians(lon2)\n",
        "\n",
        "    # Difference in coordinates\n",
        "    dlat = lat2_rad - lat1_rad\n",
        "    dlon = lon2_rad - lon1_rad\n",
        "\n",
        "    # Haversine formula\n",
        "    a = math.sin(dlat / 2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2)**2\n",
        "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
        "\n",
        "    # Distance in kilometers\n",
        "    distance = R * c\n",
        "    return distance\n",
        "\n",
        "# Register the Haversine function as a UDF (User Defined Function)\n",
        "haversine_udf = udf(haversine, DoubleType())\n",
        "\n",
        "# Assuming you have already loaded the dataset `df`\n",
        "# If you have more columns, let's make sure that we keep them all\n",
        "\n",
        "# Example to load your dataset into DataFrame (replace 'file_path' with the actual path)\n",
        "# Reading CSV data into a Spark DataFrame\n",
        "df1 = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Apply the Haversine UDF to calculate the distance and keep all original columns\n",
        "df_with_distance = df1.withColumn(\"distance_from_merchant\",\n",
        "                                 haversine_udf(\"lat\", \"long\", \"merch_lat\", \"merch_long\"))\n",
        "\n",
        "# Show the resulting DataFrame with the calculated distance, along with all original columns\n",
        "df_with_distance.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUqMkgn8ml2o",
        "outputId": "9871f4b4-415b-4043-bbe6-6b890163c12b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------------------+-------------------+----------------------------------------+-------------+------+-----------+---------+------+------------------------------+------------------------+-----+-----+-------+------------------+--------+---------------------------------------------+----------+--------------------------------+----------+------------------+------------------+--------+----------------------+\n",
            "|_c0|trans_date_trans_time|cc_num             |merchant                                |category     |amt   |first      |last     |gender|street                        |city                    |state|zip  |lat    |long              |city_pop|job                                          |dob       |trans_num                       |unix_time |merch_lat         |merch_long        |is_fraud|distance_from_merchant|\n",
            "+---+---------------------+-------------------+----------------------------------------+-------------+------+-----------+---------+------+------------------------------+------------------------+-----+-----+-------+------------------+--------+---------------------------------------------+----------+--------------------------------+----------+------------------+------------------+--------+----------------------+\n",
            "|0  |2019-01-01 00:00:18  |2703186189652095   |fraud_Rippin, Kub and Mann              |misc_net     |4.97  |Jennifer   |Banks    |F     |561 Perry Cove                |Moravian Falls          |NC   |28654|36.0788|-81.1781          |3495    |Psychologist, counselling                    |1988-03-09|0b242abb623afc578575680df30655b9|1325376018|36.011293         |-82.048315        |0       |78.59756848823062     |\n",
            "|1  |2019-01-01 00:00:44  |630423337322       |fraud_Heller, Gutmann and Zieme         |grocery_pos  |107.23|Stephanie  |Gill     |F     |43039 Riley Greens Suite 393  |Orient                  |WA   |99160|48.8878|-118.2105         |149     |Special educational needs teacher            |1978-06-21|1f76529f8574734946361c461b024d99|1325376044|49.159046999999994|-118.186462       |0       |30.212175719210443    |\n",
            "|2  |2019-01-01 00:00:51  |38859492057661     |fraud_Lind-Buckridge                    |entertainment|220.11|Edward     |Sanchez  |M     |594 White Dale Suite 530      |Malad City              |ID   |83252|42.1808|-112.262          |4154    |Nature conservation officer                  |1962-01-19|a1a22d70485983eac12b5b88dad1cf95|1325376051|43.150704         |-112.154481       |0       |108.20608258720067    |\n",
            "|3  |2019-01-01 00:01:16  |3534093764340240   |fraud_Kutch, Hermiston and Farrell      |gas_transport|45.0  |Jeremy     |White    |M     |9443 Cynthia Court Apt. 038   |Boulder                 |MT   |59632|46.2306|-112.1138         |1939    |Patent attorney                              |1967-01-12|6b849c168bdad6f867558c3793159a81|1325376076|47.034331         |-112.561071       |0       |95.67323113819748     |\n",
            "|4  |2019-01-01 00:03:06  |375534208663984    |fraud_Keeling-Crist                     |misc_pos     |41.96 |Tyler      |Garcia   |M     |408 Bradley Rest              |Doe Hill                |VA   |24433|38.4207|-79.4629          |99      |Dance movement psychotherapist               |1986-03-28|a41d7549acf90789359a9aa5346dcb46|1325376186|38.674999         |-78.632459        |0       |77.5567436258178      |\n",
            "|5  |2019-01-01 00:04:08  |4767265376804500   |fraud_Stroman, Hudson and Erdman        |gas_transport|94.63 |Jennifer   |Conner   |F     |4655 David Island             |Dublin                  |PA   |18917|40.375 |-75.2045          |2158    |Transport planner                            |1961-06-19|189a841a0a8ba03058526bcfe566aab5|1325376248|40.653382         |-76.15266700000001|0       |85.92264266264023     |\n",
            "|6  |2019-01-01 00:04:42  |30074693890476     |fraud_Rowe-Vandervort                   |grocery_net  |44.54 |Kelsey     |Richards |F     |889 Sarah Station Suite 624   |Holcomb                 |KS   |67851|37.9931|-100.9893         |2691    |Arboriculturist                              |1993-08-16|83ec1cc84142af6e2acf10c44949e720|1325376282|37.162704999999995|-100.15337        |0       |118.11977555909641    |\n",
            "|7  |2019-01-01 00:05:08  |6011360759745864   |fraud_Corwin-Collins                    |gas_transport|71.65 |Steven     |Williams |M     |231 Flores Pass Suite 720     |Edinburg                |VA   |22824|38.8432|-78.6003          |6018    |Designer, multimedia                         |1947-08-21|6d294ed2cc447d2c71c7171a3d54967c|1325376308|38.948089         |-78.540296        |0       |12.766922541959126    |\n",
            "|8  |2019-01-01 00:05:18  |4922710831011201   |fraud_Herzog Ltd                        |misc_pos     |4.27  |Heather    |Chase    |F     |6888 Hicks Stream Suite 954   |Manor                   |PA   |15665|40.3359|-79.6607          |1472    |Public affairs consultant                    |1941-03-07|fc28024ce480f8ef21a32d64c93a29f5|1325376318|40.351813         |-79.958146        |0       |25.27049367104955     |\n",
            "|9  |2019-01-01 00:06:01  |2720830304681674   |fraud_Schoen, Kuphal and Nitzsche       |grocery_pos  |198.39|Melissa    |Aguilar  |F     |21326 Taylor Squares Suite 708|Clarksville             |TN   |37040|36.522 |-87.34899999999999|151785  |Pathologist                                  |1974-03-28|3b9014ea8fb80bd65de0b1463b00b00e|1325376361|37.179198         |-87.485381        |0       |74.07775048182131     |\n",
            "|10 |2019-01-01 00:06:23  |4642894980163      |fraud_Rutherford-Mertz                  |grocery_pos  |24.74 |Eddie      |Mendez   |M     |1831 Faith View Suite 653     |Clarinda                |IA   |51632|40.7491|-95.038           |7297    |IT trainer                                   |1990-07-13|d71c95ab6b7356dd74389d41df429c87|1325376383|40.275890999999994|-96.011548        |0       |97.68326577207269     |\n",
            "|11 |2019-01-01 00:06:53  |377234009633447    |fraud_Kerluke-Abshire                   |shopping_net |7.77  |Theresa    |Blackwell|F     |43576 Kristina Islands        |Shenandoah Junction     |WV   |25442|39.3716|-77.8229          |1925    |Systems developer                            |1966-02-14|3c74776e558f1499a7824b556e474b1d|1325376413|40.103866         |-78.624459        |0       |106.4293808943283     |\n",
            "|12 |2019-01-01 00:06:56  |180042946491150    |fraud_Lockman Ltd                       |grocery_pos  |71.22 |Charles    |Robles   |M     |3337 Lisa Divide              |Saint Petersburg        |FL   |33710|27.7898|-82.7243          |341043  |Engineer, land                               |1989-02-28|c1d9a7ddb1e34639fe82758de97f4abf|1325376416|27.630593         |-82.308891        |0       |44.56107983071174     |\n",
            "|13 |2019-01-01 00:07:27  |5559857416065248   |fraud_Kiehn Inc                         |grocery_pos  |96.29 |Jack       |Hill     |M     |5916 Susan Bridge Apt. 939    |Grenada                 |CA   |96038|41.6125|-122.5258         |589     |Systems analyst                              |1945-12-21|413636e759663f264aae1819a4d4f231|1325376447|41.65752          |-122.230347       |0       |25.059079169313318    |\n",
            "|14 |2019-01-01 00:09:03  |3514865930894695   |fraud_Beier-Hyatt                       |shopping_pos |7.77  |Christopher|Castaneda|M     |1632 Cohen Drive Suite 639    |High Rolls Mountain Park|NM   |88325|32.9396|-105.8189         |899     |Naval architect                              |1967-08-30|8a6293af5ed278dea14448ded2685fea|1325376543|32.863258         |-106.520205       |0       |66.02168481006179     |\n",
            "|15 |2019-01-01 00:09:20  |6011999606625827   |fraud_Schmidt and Sons                  |shopping_net |3.26  |Ronald     |Carson   |M     |870 Rocha Drive               |Harrington Park         |NJ   |7640 |40.9918|-73.98            |4664    |Radiographer, diagnostic                     |1965-06-30|baae0b096835c975857eea7e28dde3dc|1325376560|41.831174         |-74.335559        |0       |97.93065268602581     |\n",
            "|16 |2019-01-01 00:10:49  |6011860238257910   |fraud_Lebsack and Sons                  |misc_net     |327.0 |Lisa       |Mendez   |F     |44259 Beth Station Suite 215  |Lahoma                  |OK   |73754|36.385 |-98.0727          |1078    |Programme researcher, broadcasting/film/video|1952-07-06|991c04803b4d4eeab30d6245a872e3d3|1325376649|36.384091999999995|-99.048472        |0       |87.34874840731703     |\n",
            "|17 |2019-01-01 00:10:58  |3565423334076143   |fraud_Mayert Group                      |shopping_pos |341.67|Nathan     |Thomas   |M     |4923 Campbell Pines Suite 717 |Carlisle                |IN   |47838|38.9763|-87.3667          |4081    |Energy engineer                              |1938-03-15|f12cf52be2175703db789a4644c32f25|1325376658|38.674490999999996|-88.305767        |0       |87.99895015911639     |\n",
            "|18 |2019-01-01 00:11:14  |2348245054386329   |fraud_Konopelski, Schneider and Hartmann|food_dining  |63.07 |Justin     |Gay      |M     |268 Hayes Rue Suite 811       |Harborcreek             |PA   |16421|42.1767|-79.9416          |2518    |Event organiser                              |1946-02-02|8500f3d459047eac8443307b1e8296e5|1325376674|41.430274         |-79.492553        |0       |90.96220878947973     |\n",
            "|19 |2019-01-01 00:12:34  |4956828990005111019|fraud_Schultz, Simonis and Little       |grocery_pos  |44.71 |Kenneth    |Robinson |M     |269 Sanchez Rapids            |Elizabeth               |NJ   |7208 |40.6747|-74.2239          |124967  |Operational researcher                       |1980-12-21|09eff9c806365e2a6be12c1bbab3d70e|1325376754|40.079588         |-74.84808699999999|0       |84.70212030854243     |\n",
            "+---+---------------------+-------------------+----------------------------------------+-------------+------+-----------+---------+------+------------------------------+------------------------+-----+-----+-------+------------------+--------+---------------------------------------------+----------+--------------------------------+----------+------------------+------------------+--------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print schema to see column names and types\n",
        "df_with_distance.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V8ke2z6nIGV",
        "outputId": "fa598f75-ef24-45cd-9ddc-1d126c4b1dd3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- trans_date_trans_time: timestamp (nullable = true)\n",
            " |-- cc_num: long (nullable = true)\n",
            " |-- merchant: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- amt: double (nullable = true)\n",
            " |-- first: string (nullable = true)\n",
            " |-- last: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- street: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- zip: integer (nullable = true)\n",
            " |-- lat: double (nullable = true)\n",
            " |-- long: double (nullable = true)\n",
            " |-- city_pop: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- dob: date (nullable = true)\n",
            " |-- trans_num: string (nullable = true)\n",
            " |-- unix_time: integer (nullable = true)\n",
            " |-- merch_lat: double (nullable = true)\n",
            " |-- merch_long: double (nullable = true)\n",
            " |-- is_fraud: integer (nullable = true)\n",
            " |-- distance_from_merchant: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unwanted columns from df_with_distance\n",
        "df_cleaned = df_with_distance.drop('_c0', 'merchant', 'cc_num', 'first',\n",
        "                                   'state', 'last', 'trans_num', 'unix_time',\n",
        "                                   'street', 'city', 'lat', 'long', 'merch_lat',\n",
        "                                   'merch_long', 'zip')\n",
        "\n",
        "# Show the cleaned DataFrame with the remaining columns\n",
        "df_cleaned.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0UTbjL3neBl",
        "outputId": "4ba48653-d7fb-4cd3-dba3-9d60e30968d7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+-------------+------+------+--------+---------------------------------------------+----------+--------+----------------------+\n",
            "|trans_date_trans_time|category     |amt   |gender|city_pop|job                                          |dob       |is_fraud|distance_from_merchant|\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+----------+--------+----------------------+\n",
            "|2019-01-01 00:00:18  |misc_net     |4.97  |F     |3495    |Psychologist, counselling                    |1988-03-09|0       |78.59756848823062     |\n",
            "|2019-01-01 00:00:44  |grocery_pos  |107.23|F     |149     |Special educational needs teacher            |1978-06-21|0       |30.212175719210443    |\n",
            "|2019-01-01 00:00:51  |entertainment|220.11|M     |4154    |Nature conservation officer                  |1962-01-19|0       |108.20608258720067    |\n",
            "|2019-01-01 00:01:16  |gas_transport|45.0  |M     |1939    |Patent attorney                              |1967-01-12|0       |95.67323113819748     |\n",
            "|2019-01-01 00:03:06  |misc_pos     |41.96 |M     |99      |Dance movement psychotherapist               |1986-03-28|0       |77.5567436258178      |\n",
            "|2019-01-01 00:04:08  |gas_transport|94.63 |F     |2158    |Transport planner                            |1961-06-19|0       |85.92264266264023     |\n",
            "|2019-01-01 00:04:42  |grocery_net  |44.54 |F     |2691    |Arboriculturist                              |1993-08-16|0       |118.11977555909641    |\n",
            "|2019-01-01 00:05:08  |gas_transport|71.65 |M     |6018    |Designer, multimedia                         |1947-08-21|0       |12.766922541959126    |\n",
            "|2019-01-01 00:05:18  |misc_pos     |4.27  |F     |1472    |Public affairs consultant                    |1941-03-07|0       |25.27049367104955     |\n",
            "|2019-01-01 00:06:01  |grocery_pos  |198.39|F     |151785  |Pathologist                                  |1974-03-28|0       |74.07775048182131     |\n",
            "|2019-01-01 00:06:23  |grocery_pos  |24.74 |M     |7297    |IT trainer                                   |1990-07-13|0       |97.68326577207269     |\n",
            "|2019-01-01 00:06:53  |shopping_net |7.77  |F     |1925    |Systems developer                            |1966-02-14|0       |106.4293808943283     |\n",
            "|2019-01-01 00:06:56  |grocery_pos  |71.22 |M     |341043  |Engineer, land                               |1989-02-28|0       |44.56107983071174     |\n",
            "|2019-01-01 00:07:27  |grocery_pos  |96.29 |M     |589     |Systems analyst                              |1945-12-21|0       |25.059079169313318    |\n",
            "|2019-01-01 00:09:03  |shopping_pos |7.77  |M     |899     |Naval architect                              |1967-08-30|0       |66.02168481006179     |\n",
            "|2019-01-01 00:09:20  |shopping_net |3.26  |M     |4664    |Radiographer, diagnostic                     |1965-06-30|0       |97.93065268602581     |\n",
            "|2019-01-01 00:10:49  |misc_net     |327.0 |F     |1078    |Programme researcher, broadcasting/film/video|1952-07-06|0       |87.34874840731703     |\n",
            "|2019-01-01 00:10:58  |shopping_pos |341.67|M     |4081    |Energy engineer                              |1938-03-15|0       |87.99895015911639     |\n",
            "|2019-01-01 00:11:14  |food_dining  |63.07 |M     |2518    |Event organiser                              |1946-02-02|0       |90.96220878947973     |\n",
            "|2019-01-01 00:12:34  |grocery_pos  |44.71 |M     |124967  |Operational researcher                       |1980-12-21|0       |84.70212030854243     |\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+----------+--------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import to_timestamp\n",
        "\n",
        "# Convert 'trans_date_trans_time' to timestamp\n",
        "df_cleaned = df_cleaned.withColumn('trans_date_trans_time', to_timestamp('trans_date_trans_time'))\n",
        "\n",
        "# Convert 'dob' to timestamp\n",
        "df_cleaned = df_cleaned.withColumn('dob', to_timestamp('dob'))\n",
        "\n",
        "# Show the updated DataFrame schema to verify the changes\n",
        "df_cleaned.printSchema()\n",
        "\n",
        "# Show the DataFrame to verify the conversions\n",
        "df_cleaned.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIYdA4ibpsrm",
        "outputId": "7c4232e4-f35c-4990-ea81-4ec40caed1d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- trans_date_trans_time: timestamp (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- amt: double (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- city_pop: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- dob: timestamp (nullable = true)\n",
            " |-- is_fraud: integer (nullable = true)\n",
            " |-- distance_from_merchant: double (nullable = true)\n",
            "\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+-------------------+--------+----------------------+\n",
            "|trans_date_trans_time|category     |amt   |gender|city_pop|job                                          |dob                |is_fraud|distance_from_merchant|\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+-------------------+--------+----------------------+\n",
            "|2019-01-01 00:00:18  |misc_net     |4.97  |F     |3495    |Psychologist, counselling                    |1988-03-09 00:00:00|0       |78.59756848823062     |\n",
            "|2019-01-01 00:00:44  |grocery_pos  |107.23|F     |149     |Special educational needs teacher            |1978-06-21 00:00:00|0       |30.212175719210443    |\n",
            "|2019-01-01 00:00:51  |entertainment|220.11|M     |4154    |Nature conservation officer                  |1962-01-19 00:00:00|0       |108.20608258720067    |\n",
            "|2019-01-01 00:01:16  |gas_transport|45.0  |M     |1939    |Patent attorney                              |1967-01-12 00:00:00|0       |95.67323113819748     |\n",
            "|2019-01-01 00:03:06  |misc_pos     |41.96 |M     |99      |Dance movement psychotherapist               |1986-03-28 00:00:00|0       |77.5567436258178      |\n",
            "|2019-01-01 00:04:08  |gas_transport|94.63 |F     |2158    |Transport planner                            |1961-06-19 00:00:00|0       |85.92264266264023     |\n",
            "|2019-01-01 00:04:42  |grocery_net  |44.54 |F     |2691    |Arboriculturist                              |1993-08-16 00:00:00|0       |118.11977555909641    |\n",
            "|2019-01-01 00:05:08  |gas_transport|71.65 |M     |6018    |Designer, multimedia                         |1947-08-21 00:00:00|0       |12.766922541959126    |\n",
            "|2019-01-01 00:05:18  |misc_pos     |4.27  |F     |1472    |Public affairs consultant                    |1941-03-07 00:00:00|0       |25.27049367104955     |\n",
            "|2019-01-01 00:06:01  |grocery_pos  |198.39|F     |151785  |Pathologist                                  |1974-03-28 00:00:00|0       |74.07775048182131     |\n",
            "|2019-01-01 00:06:23  |grocery_pos  |24.74 |M     |7297    |IT trainer                                   |1990-07-13 00:00:00|0       |97.68326577207269     |\n",
            "|2019-01-01 00:06:53  |shopping_net |7.77  |F     |1925    |Systems developer                            |1966-02-14 00:00:00|0       |106.4293808943283     |\n",
            "|2019-01-01 00:06:56  |grocery_pos  |71.22 |M     |341043  |Engineer, land                               |1989-02-28 00:00:00|0       |44.56107983071174     |\n",
            "|2019-01-01 00:07:27  |grocery_pos  |96.29 |M     |589     |Systems analyst                              |1945-12-21 00:00:00|0       |25.059079169313318    |\n",
            "|2019-01-01 00:09:03  |shopping_pos |7.77  |M     |899     |Naval architect                              |1967-08-30 00:00:00|0       |66.02168481006179     |\n",
            "|2019-01-01 00:09:20  |shopping_net |3.26  |M     |4664    |Radiographer, diagnostic                     |1965-06-30 00:00:00|0       |97.93065268602581     |\n",
            "|2019-01-01 00:10:49  |misc_net     |327.0 |F     |1078    |Programme researcher, broadcasting/film/video|1952-07-06 00:00:00|0       |87.34874840731703     |\n",
            "|2019-01-01 00:10:58  |shopping_pos |341.67|M     |4081    |Energy engineer                              |1938-03-15 00:00:00|0       |87.99895015911639     |\n",
            "|2019-01-01 00:11:14  |food_dining  |63.07 |M     |2518    |Event organiser                              |1946-02-02 00:00:00|0       |90.96220878947973     |\n",
            "|2019-01-01 00:12:34  |grocery_pos  |44.71 |M     |124967  |Operational researcher                       |1980-12-21 00:00:00|0       |84.70212030854243     |\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+-------------------+--------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import year, month, dayofmonth, current_date\n",
        "\n",
        "# Extract individual date-time components from 'trans_date_trans_time'\n",
        "df_cleaned = df_cleaned.withColumn('year', year('trans_date_trans_time'))\n",
        "df_cleaned = df_cleaned.withColumn('Trans_month', month('trans_date_trans_time'))\n",
        "\n",
        "# Extract individual date-time components from 'dob'\n",
        "df_cleaned = df_cleaned.withColumn('birth_year', year('dob'))\n",
        "\n",
        "# Calculate age by subtracting birth year from the current year\n",
        "current_year = current_date().substr(1, 4).cast('int')  # Extract current year as integer\n",
        "df_cleaned = df_cleaned.withColumn('age', current_year - df_cleaned['birth_year'])\n",
        "\n",
        "# Show the updated DataFrame with the new columns\n",
        "df_cleaned.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qoxy8l0lp0Hf",
        "outputId": "f91f2859-de5c-4319-df86-e3d1da3a02e7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+-------------+------+------+--------+---------------------------------------------+-------------------+--------+----------------------+----+-----------+----------+---+\n",
            "|trans_date_trans_time|category     |amt   |gender|city_pop|job                                          |dob                |is_fraud|distance_from_merchant|year|Trans_month|birth_year|age|\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+-------------------+--------+----------------------+----+-----------+----------+---+\n",
            "|2019-01-01 00:00:18  |misc_net     |4.97  |F     |3495    |Psychologist, counselling                    |1988-03-09 00:00:00|0       |78.59756848823062     |2019|1          |1988      |36 |\n",
            "|2019-01-01 00:00:44  |grocery_pos  |107.23|F     |149     |Special educational needs teacher            |1978-06-21 00:00:00|0       |30.212175719210443    |2019|1          |1978      |46 |\n",
            "|2019-01-01 00:00:51  |entertainment|220.11|M     |4154    |Nature conservation officer                  |1962-01-19 00:00:00|0       |108.20608258720067    |2019|1          |1962      |62 |\n",
            "|2019-01-01 00:01:16  |gas_transport|45.0  |M     |1939    |Patent attorney                              |1967-01-12 00:00:00|0       |95.67323113819748     |2019|1          |1967      |57 |\n",
            "|2019-01-01 00:03:06  |misc_pos     |41.96 |M     |99      |Dance movement psychotherapist               |1986-03-28 00:00:00|0       |77.5567436258178      |2019|1          |1986      |38 |\n",
            "|2019-01-01 00:04:08  |gas_transport|94.63 |F     |2158    |Transport planner                            |1961-06-19 00:00:00|0       |85.92264266264023     |2019|1          |1961      |63 |\n",
            "|2019-01-01 00:04:42  |grocery_net  |44.54 |F     |2691    |Arboriculturist                              |1993-08-16 00:00:00|0       |118.11977555909641    |2019|1          |1993      |31 |\n",
            "|2019-01-01 00:05:08  |gas_transport|71.65 |M     |6018    |Designer, multimedia                         |1947-08-21 00:00:00|0       |12.766922541959126    |2019|1          |1947      |77 |\n",
            "|2019-01-01 00:05:18  |misc_pos     |4.27  |F     |1472    |Public affairs consultant                    |1941-03-07 00:00:00|0       |25.27049367104955     |2019|1          |1941      |83 |\n",
            "|2019-01-01 00:06:01  |grocery_pos  |198.39|F     |151785  |Pathologist                                  |1974-03-28 00:00:00|0       |74.07775048182131     |2019|1          |1974      |50 |\n",
            "|2019-01-01 00:06:23  |grocery_pos  |24.74 |M     |7297    |IT trainer                                   |1990-07-13 00:00:00|0       |97.68326577207269     |2019|1          |1990      |34 |\n",
            "|2019-01-01 00:06:53  |shopping_net |7.77  |F     |1925    |Systems developer                            |1966-02-14 00:00:00|0       |106.4293808943283     |2019|1          |1966      |58 |\n",
            "|2019-01-01 00:06:56  |grocery_pos  |71.22 |M     |341043  |Engineer, land                               |1989-02-28 00:00:00|0       |44.56107983071174     |2019|1          |1989      |35 |\n",
            "|2019-01-01 00:07:27  |grocery_pos  |96.29 |M     |589     |Systems analyst                              |1945-12-21 00:00:00|0       |25.059079169313318    |2019|1          |1945      |79 |\n",
            "|2019-01-01 00:09:03  |shopping_pos |7.77  |M     |899     |Naval architect                              |1967-08-30 00:00:00|0       |66.02168481006179     |2019|1          |1967      |57 |\n",
            "|2019-01-01 00:09:20  |shopping_net |3.26  |M     |4664    |Radiographer, diagnostic                     |1965-06-30 00:00:00|0       |97.93065268602581     |2019|1          |1965      |59 |\n",
            "|2019-01-01 00:10:49  |misc_net     |327.0 |F     |1078    |Programme researcher, broadcasting/film/video|1952-07-06 00:00:00|0       |87.34874840731703     |2019|1          |1952      |72 |\n",
            "|2019-01-01 00:10:58  |shopping_pos |341.67|M     |4081    |Energy engineer                              |1938-03-15 00:00:00|0       |87.99895015911639     |2019|1          |1938      |86 |\n",
            "|2019-01-01 00:11:14  |food_dining  |63.07 |M     |2518    |Event organiser                              |1946-02-02 00:00:00|0       |90.96220878947973     |2019|1          |1946      |78 |\n",
            "|2019-01-01 00:12:34  |grocery_pos  |44.71 |M     |124967  |Operational researcher                       |1980-12-21 00:00:00|0       |84.70212030854243     |2019|1          |1980      |44 |\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+-------------------+--------+----------------------+----+-----------+----------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Convert 'year' and 'Trans_month' columns to string (PySpark equivalent of 'object' in Pandas)\n",
        "df_cleaned = df_cleaned.withColumn('year', col('year').cast('string'))\n",
        "df_cleaned = df_cleaned.withColumn('Trans_month', col('Trans_month').cast('string'))\n",
        "\n",
        "# Show the updated DataFrame with the new column types\n",
        "df_cleaned.printSchema()\n",
        "df_cleaned.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0LqjAAaqLk8",
        "outputId": "5559cfb7-8fe2-4f28-d63f-f5c5a5c345b5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- trans_date_trans_time: timestamp (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- amt: double (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- city_pop: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- dob: timestamp (nullable = true)\n",
            " |-- is_fraud: integer (nullable = true)\n",
            " |-- distance_from_merchant: double (nullable = true)\n",
            " |-- year: string (nullable = true)\n",
            " |-- Trans_month: string (nullable = true)\n",
            " |-- birth_year: integer (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            "\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+-------------------+--------+----------------------+----+-----------+----------+---+\n",
            "|trans_date_trans_time|category     |amt   |gender|city_pop|job                                          |dob                |is_fraud|distance_from_merchant|year|Trans_month|birth_year|age|\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+-------------------+--------+----------------------+----+-----------+----------+---+\n",
            "|2019-01-01 00:00:18  |misc_net     |4.97  |F     |3495    |Psychologist, counselling                    |1988-03-09 00:00:00|0       |78.59756848823062     |2019|1          |1988      |36 |\n",
            "|2019-01-01 00:00:44  |grocery_pos  |107.23|F     |149     |Special educational needs teacher            |1978-06-21 00:00:00|0       |30.212175719210443    |2019|1          |1978      |46 |\n",
            "|2019-01-01 00:00:51  |entertainment|220.11|M     |4154    |Nature conservation officer                  |1962-01-19 00:00:00|0       |108.20608258720067    |2019|1          |1962      |62 |\n",
            "|2019-01-01 00:01:16  |gas_transport|45.0  |M     |1939    |Patent attorney                              |1967-01-12 00:00:00|0       |95.67323113819748     |2019|1          |1967      |57 |\n",
            "|2019-01-01 00:03:06  |misc_pos     |41.96 |M     |99      |Dance movement psychotherapist               |1986-03-28 00:00:00|0       |77.5567436258178      |2019|1          |1986      |38 |\n",
            "|2019-01-01 00:04:08  |gas_transport|94.63 |F     |2158    |Transport planner                            |1961-06-19 00:00:00|0       |85.92264266264023     |2019|1          |1961      |63 |\n",
            "|2019-01-01 00:04:42  |grocery_net  |44.54 |F     |2691    |Arboriculturist                              |1993-08-16 00:00:00|0       |118.11977555909641    |2019|1          |1993      |31 |\n",
            "|2019-01-01 00:05:08  |gas_transport|71.65 |M     |6018    |Designer, multimedia                         |1947-08-21 00:00:00|0       |12.766922541959126    |2019|1          |1947      |77 |\n",
            "|2019-01-01 00:05:18  |misc_pos     |4.27  |F     |1472    |Public affairs consultant                    |1941-03-07 00:00:00|0       |25.27049367104955     |2019|1          |1941      |83 |\n",
            "|2019-01-01 00:06:01  |grocery_pos  |198.39|F     |151785  |Pathologist                                  |1974-03-28 00:00:00|0       |74.07775048182131     |2019|1          |1974      |50 |\n",
            "|2019-01-01 00:06:23  |grocery_pos  |24.74 |M     |7297    |IT trainer                                   |1990-07-13 00:00:00|0       |97.68326577207269     |2019|1          |1990      |34 |\n",
            "|2019-01-01 00:06:53  |shopping_net |7.77  |F     |1925    |Systems developer                            |1966-02-14 00:00:00|0       |106.4293808943283     |2019|1          |1966      |58 |\n",
            "|2019-01-01 00:06:56  |grocery_pos  |71.22 |M     |341043  |Engineer, land                               |1989-02-28 00:00:00|0       |44.56107983071174     |2019|1          |1989      |35 |\n",
            "|2019-01-01 00:07:27  |grocery_pos  |96.29 |M     |589     |Systems analyst                              |1945-12-21 00:00:00|0       |25.059079169313318    |2019|1          |1945      |79 |\n",
            "|2019-01-01 00:09:03  |shopping_pos |7.77  |M     |899     |Naval architect                              |1967-08-30 00:00:00|0       |66.02168481006179     |2019|1          |1967      |57 |\n",
            "|2019-01-01 00:09:20  |shopping_net |3.26  |M     |4664    |Radiographer, diagnostic                     |1965-06-30 00:00:00|0       |97.93065268602581     |2019|1          |1965      |59 |\n",
            "|2019-01-01 00:10:49  |misc_net     |327.0 |F     |1078    |Programme researcher, broadcasting/film/video|1952-07-06 00:00:00|0       |87.34874840731703     |2019|1          |1952      |72 |\n",
            "|2019-01-01 00:10:58  |shopping_pos |341.67|M     |4081    |Energy engineer                              |1938-03-15 00:00:00|0       |87.99895015911639     |2019|1          |1938      |86 |\n",
            "|2019-01-01 00:11:14  |food_dining  |63.07 |M     |2518    |Event organiser                              |1946-02-02 00:00:00|0       |90.96220878947973     |2019|1          |1946      |78 |\n",
            "|2019-01-01 00:12:34  |grocery_pos  |44.71 |M     |124967  |Operational researcher                       |1980-12-21 00:00:00|0       |84.70212030854243     |2019|1          |1980      |44 |\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+-------------------+--------+----------------------+----+-----------+----------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop specified columns from df_cleaned\n",
        "df_cleaned = df_cleaned.drop('trans_date_trans_time', 'birth_year', 'dob', 'job')\n",
        "\n",
        "# Show the cleaned DataFrame to verify the columns have been removed\n",
        "df_cleaned.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJKHUhY7qMTY",
        "outputId": "1498ff41-8164-47a4-d836-6a4e42e3b0e3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------+------+--------+--------+----------------------+----+-----------+---+\n",
            "|category     |amt   |gender|city_pop|is_fraud|distance_from_merchant|year|Trans_month|age|\n",
            "+-------------+------+------+--------+--------+----------------------+----+-----------+---+\n",
            "|misc_net     |4.97  |F     |3495    |0       |78.59756848823062     |2019|1          |36 |\n",
            "|grocery_pos  |107.23|F     |149     |0       |30.212175719210443    |2019|1          |46 |\n",
            "|entertainment|220.11|M     |4154    |0       |108.20608258720067    |2019|1          |62 |\n",
            "|gas_transport|45.0  |M     |1939    |0       |95.67323113819748     |2019|1          |57 |\n",
            "|misc_pos     |41.96 |M     |99      |0       |77.5567436258178      |2019|1          |38 |\n",
            "|gas_transport|94.63 |F     |2158    |0       |85.92264266264023     |2019|1          |63 |\n",
            "|grocery_net  |44.54 |F     |2691    |0       |118.11977555909641    |2019|1          |31 |\n",
            "|gas_transport|71.65 |M     |6018    |0       |12.766922541959126    |2019|1          |77 |\n",
            "|misc_pos     |4.27  |F     |1472    |0       |25.27049367104955     |2019|1          |83 |\n",
            "|grocery_pos  |198.39|F     |151785  |0       |74.07775048182131     |2019|1          |50 |\n",
            "|grocery_pos  |24.74 |M     |7297    |0       |97.68326577207269     |2019|1          |34 |\n",
            "|shopping_net |7.77  |F     |1925    |0       |106.4293808943283     |2019|1          |58 |\n",
            "|grocery_pos  |71.22 |M     |341043  |0       |44.56107983071174     |2019|1          |35 |\n",
            "|grocery_pos  |96.29 |M     |589     |0       |25.059079169313318    |2019|1          |79 |\n",
            "|shopping_pos |7.77  |M     |899     |0       |66.02168481006179     |2019|1          |57 |\n",
            "|shopping_net |3.26  |M     |4664    |0       |97.93065268602581     |2019|1          |59 |\n",
            "|misc_net     |327.0 |F     |1078    |0       |87.34874840731703     |2019|1          |72 |\n",
            "|shopping_pos |341.67|M     |4081    |0       |87.99895015911639     |2019|1          |86 |\n",
            "|food_dining  |63.07 |M     |2518    |0       |90.96220878947973     |2019|1          |78 |\n",
            "|grocery_pos  |44.71 |M     |124967  |0       |84.70212030854243     |2019|1          |44 |\n",
            "+-------------+------+------+--------+--------+----------------------+----+-----------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import max\n",
        "\n",
        "# Find the maximum value of 'city_pop' column\n",
        "max_city_pop = df_cleaned.agg(max('city_pop')).collect()[0][0]\n",
        "\n",
        "# Print the maximum value\n",
        "print(\"Maximum value of 'city_pop':\", max_city_pop)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl83bEubqZRi",
        "outputId": "614de71b-9122-4362-8fe9-99750798ebb1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum value of 'city_pop': 2906700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Define the population thresholds\n",
        "rural_threshold = 1000000  # Population < 1 million\n",
        "metropolitan_threshold = 5000000  # Population > 5 million\n",
        "\n",
        "# Create a new 'city_type' column based on population\n",
        "df_cleaned = df_cleaned.withColumn(\n",
        "    'city_type',\n",
        "    F.when(df_cleaned['city_pop'] < rural_threshold, '1')  # Cities with < 1M population\n",
        "     .when((df_cleaned['city_pop'] >= rural_threshold) & (df_cleaned['city_pop'] < metropolitan_threshold), '2')  # Cities between 1M and 5M population\n",
        "     .otherwise('3')  # Cities with > 5M population\n",
        ")\n",
        "\n",
        "'''\n",
        "1 - rural\n",
        "2 - subarban\n",
        "3 - metropolitan\n",
        "'''\n",
        "\n",
        "# Show the updated DataFrame with the new 'city_type' column\n",
        "df_cleaned.select('city_pop', 'city_type').show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaTnF-wEqq8M",
        "outputId": "b3ee88d3-b343-4657-9415-b0d05d4a8816"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+\n",
            "|city_pop|city_type|\n",
            "+--------+---------+\n",
            "|3495    |1        |\n",
            "|149     |1        |\n",
            "|4154    |1        |\n",
            "|1939    |1        |\n",
            "|99      |1        |\n",
            "|2158    |1        |\n",
            "|2691    |1        |\n",
            "|6018    |1        |\n",
            "|1472    |1        |\n",
            "|151785  |1        |\n",
            "|7297    |1        |\n",
            "|1925    |1        |\n",
            "|341043  |1        |\n",
            "|589     |1        |\n",
            "|899     |1        |\n",
            "|4664    |1        |\n",
            "|1078    |1        |\n",
            "|4081    |1        |\n",
            "|2518    |1        |\n",
            "|124967  |1        |\n",
            "+--------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop specified columns from df_cleaned\n",
        "df_cleaned = df_cleaned.drop('city_pop')\n",
        "\n",
        "# Show the cleaned DataFrame to verify the columns have been removed\n",
        "df_cleaned.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNn3rmphsmx8",
        "outputId": "8de73fab-1f67-4241-b2d1-206fc15cce65"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------+------+--------+----------------------+----+-----------+---+---------+\n",
            "|category     |amt   |gender|is_fraud|distance_from_merchant|year|Trans_month|age|city_type|\n",
            "+-------------+------+------+--------+----------------------+----+-----------+---+---------+\n",
            "|misc_net     |4.97  |F     |0       |78.59756848823062     |2019|1          |36 |1        |\n",
            "|grocery_pos  |107.23|F     |0       |30.212175719210443    |2019|1          |46 |1        |\n",
            "|entertainment|220.11|M     |0       |108.20608258720067    |2019|1          |62 |1        |\n",
            "|gas_transport|45.0  |M     |0       |95.67323113819748     |2019|1          |57 |1        |\n",
            "|misc_pos     |41.96 |M     |0       |77.5567436258178      |2019|1          |38 |1        |\n",
            "|gas_transport|94.63 |F     |0       |85.92264266264023     |2019|1          |63 |1        |\n",
            "|grocery_net  |44.54 |F     |0       |118.11977555909641    |2019|1          |31 |1        |\n",
            "|gas_transport|71.65 |M     |0       |12.766922541959126    |2019|1          |77 |1        |\n",
            "|misc_pos     |4.27  |F     |0       |25.27049367104955     |2019|1          |83 |1        |\n",
            "|grocery_pos  |198.39|F     |0       |74.07775048182131     |2019|1          |50 |1        |\n",
            "|grocery_pos  |24.74 |M     |0       |97.68326577207269     |2019|1          |34 |1        |\n",
            "|shopping_net |7.77  |F     |0       |106.4293808943283     |2019|1          |58 |1        |\n",
            "|grocery_pos  |71.22 |M     |0       |44.56107983071174     |2019|1          |35 |1        |\n",
            "|grocery_pos  |96.29 |M     |0       |25.059079169313318    |2019|1          |79 |1        |\n",
            "|shopping_pos |7.77  |M     |0       |66.02168481006179     |2019|1          |57 |1        |\n",
            "|shopping_net |3.26  |M     |0       |97.93065268602581     |2019|1          |59 |1        |\n",
            "|misc_net     |327.0 |F     |0       |87.34874840731703     |2019|1          |72 |1        |\n",
            "|shopping_pos |341.67|M     |0       |87.99895015911639     |2019|1          |86 |1        |\n",
            "|food_dining  |63.07 |M     |0       |90.96220878947973     |2019|1          |78 |1        |\n",
            "|grocery_pos  |44.71 |M     |0       |84.70212030854243     |2019|1          |44 |1        |\n",
            "+-------------+------+------+--------+----------------------+----+-----------+---+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Convert 'amt' and 'distance_from_merchant' to integer (whole numbers)\n",
        "df_cleaned = df_cleaned.withColumn('amt', col('amt').cast('int'))\n",
        "df_cleaned = df_cleaned.withColumn('distance_from_merchant', col('distance_from_merchant').cast('int'))\n",
        "\n",
        "# Show the updated DataFrame with the converted columns\n",
        "df_cleaned.select('amt', 'distance_from_merchant').show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2sSdZPjs7SG",
        "outputId": "4a2cedb4-ad07-4085-d048-c0efea7b7bc1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------------+\n",
            "|amt|distance_from_merchant|\n",
            "+---+----------------------+\n",
            "|4  |78                    |\n",
            "|107|30                    |\n",
            "|220|108                   |\n",
            "|45 |95                    |\n",
            "|41 |77                    |\n",
            "|94 |85                    |\n",
            "|44 |118                   |\n",
            "|71 |12                    |\n",
            "|4  |25                    |\n",
            "|198|74                    |\n",
            "|24 |97                    |\n",
            "|7  |106                   |\n",
            "|71 |44                    |\n",
            "|96 |25                    |\n",
            "|7  |66                    |\n",
            "|3  |97                    |\n",
            "|327|87                    |\n",
            "|341|87                    |\n",
            "|63 |90                    |\n",
            "|44 |84                    |\n",
            "+---+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the cleaned DataFrame to verify the columns have been removed\n",
        "df_cleaned.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrI8GVtEtKF3",
        "outputId": "5283b53d-f61f-4059-9a90-d3fa7db1fb26"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---+------+--------+----------------------+----+-----------+---+---------+\n",
            "|category     |amt|gender|is_fraud|distance_from_merchant|year|Trans_month|age|city_type|\n",
            "+-------------+---+------+--------+----------------------+----+-----------+---+---------+\n",
            "|misc_net     |4  |F     |0       |78                    |2019|1          |36 |1        |\n",
            "|grocery_pos  |107|F     |0       |30                    |2019|1          |46 |1        |\n",
            "|entertainment|220|M     |0       |108                   |2019|1          |62 |1        |\n",
            "|gas_transport|45 |M     |0       |95                    |2019|1          |57 |1        |\n",
            "|misc_pos     |41 |M     |0       |77                    |2019|1          |38 |1        |\n",
            "|gas_transport|94 |F     |0       |85                    |2019|1          |63 |1        |\n",
            "|grocery_net  |44 |F     |0       |118                   |2019|1          |31 |1        |\n",
            "|gas_transport|71 |M     |0       |12                    |2019|1          |77 |1        |\n",
            "|misc_pos     |4  |F     |0       |25                    |2019|1          |83 |1        |\n",
            "|grocery_pos  |198|F     |0       |74                    |2019|1          |50 |1        |\n",
            "|grocery_pos  |24 |M     |0       |97                    |2019|1          |34 |1        |\n",
            "|shopping_net |7  |F     |0       |106                   |2019|1          |58 |1        |\n",
            "|grocery_pos  |71 |M     |0       |44                    |2019|1          |35 |1        |\n",
            "|grocery_pos  |96 |M     |0       |25                    |2019|1          |79 |1        |\n",
            "|shopping_pos |7  |M     |0       |66                    |2019|1          |57 |1        |\n",
            "|shopping_net |3  |M     |0       |97                    |2019|1          |59 |1        |\n",
            "|misc_net     |327|F     |0       |87                    |2019|1          |72 |1        |\n",
            "|shopping_pos |341|M     |0       |87                    |2019|1          |86 |1        |\n",
            "|food_dining  |63 |M     |0       |90                    |2019|1          |78 |1        |\n",
            "|grocery_pos  |44 |M     |0       |84                    |2019|1          |44 |1        |\n",
            "+-------------+---+------+--------+----------------------+----+-----------+---+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Map 'M' to 1 and 'F' to 0 in the 'gender' column\n",
        "df_cleaned = df_cleaned.withColumn(\n",
        "    'gender',\n",
        "    F.when(df_cleaned['gender'] == 'M', 1)\n",
        "     .when(df_cleaned['gender'] == 'F', 0)\n",
        "     .otherwise(df_cleaned['gender'])  # Keeps other values if there are any (optional)\n",
        ")\n",
        "\n",
        "# Show the updated DataFrame with the mapped 'gender' column\n",
        "df_cleaned.select('gender').show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O1XybyrtNMW",
        "outputId": "c827087b-46db-4fb7-8c05-5b891c18c859"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|gender|\n",
            "+------+\n",
            "|0     |\n",
            "|0     |\n",
            "|1     |\n",
            "|1     |\n",
            "|1     |\n",
            "|0     |\n",
            "|0     |\n",
            "|1     |\n",
            "|0     |\n",
            "|0     |\n",
            "|1     |\n",
            "|0     |\n",
            "|1     |\n",
            "|1     |\n",
            "|1     |\n",
            "|1     |\n",
            "|0     |\n",
            "|1     |\n",
            "|1     |\n",
            "|1     |\n",
            "+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show data types of all columns\n",
        "for col_name, dtype in df_cleaned.dtypes:\n",
        "    print(f\"Column: {col_name}, Type: {dtype}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCOebtumtV8a",
        "outputId": "0b36e166-8d5a-4c6d-94d4-df8a402d142d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column: category, Type: string\n",
            "Column: amt, Type: int\n",
            "Column: gender, Type: string\n",
            "Column: is_fraud, Type: int\n",
            "Column: distance_from_merchant, Type: int\n",
            "Column: year, Type: string\n",
            "Column: Trans_month, Type: string\n",
            "Column: age, Type: int\n",
            "Column: city_type, Type: string\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Convert 'gender' column to string\n",
        "df_cleaned = df_cleaned.withColumn('gender', col('gender').cast('string'))\n",
        "\n",
        "# Show the updated DataFrame with the 'gender' column as string\n",
        "df_cleaned.select('gender').show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ac1qRENOtcoY",
        "outputId": "c9bdef1f-431b-465b-c38d-40d959788c5d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|gender|\n",
            "+------+\n",
            "|0     |\n",
            "|0     |\n",
            "|1     |\n",
            "|1     |\n",
            "|1     |\n",
            "|0     |\n",
            "|0     |\n",
            "|1     |\n",
            "|0     |\n",
            "|0     |\n",
            "|1     |\n",
            "|0     |\n",
            "|1     |\n",
            "|1     |\n",
            "|1     |\n",
            "|1     |\n",
            "|0     |\n",
            "|1     |\n",
            "|1     |\n",
            "|1     |\n",
            "+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Convert 'is_fraud' column to 'Fraud' and 'Not Fraud' labels\n",
        "df_cleaned = df_cleaned.withColumn(\n",
        "    'is_fraud',\n",
        "    F.when(df_cleaned['is_fraud'] == '1', '1')\n",
        "     .when(df_cleaned['is_fraud'] == '0', '0')\n",
        "     .otherwise(df_cleaned['is_fraud'])  # Keep other values (if any)\n",
        ")\n",
        "\n",
        "# Show the updated DataFrame with the 'is_fraud' column as string\n",
        "df_cleaned.select('is_fraud').show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1ILUqapt18H",
        "outputId": "2fc5fb49-263a-480f-9792-da6fa0ae8820"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|is_fraud|\n",
            "+--------+\n",
            "|0       |\n",
            "|0       |\n",
            "|0       |\n",
            "|0       |\n",
            "|0       |\n",
            "|0       |\n",
            "|0       |\n",
            "|0       |\n",
            "|0       |\n",
            "|0       |\n",
            "|0       |\n",
            "|0       |\n",
            "|0       |\n",
            "|0       |\n",
            "|0       |\n",
            "|0       |\n",
            "|0       |\n",
            "|0       |\n",
            "|0       |\n",
            "|0       |\n",
            "+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6N8HM0PuqAP",
        "outputId": "682bcb9c-9afa-431c-9aaa-9f75e11687b8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- category: string (nullable = true)\n",
            " |-- amt: integer (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- is_fraud: string (nullable = true)\n",
            " |-- distance_from_merchant: integer (nullable = true)\n",
            " |-- year: string (nullable = true)\n",
            " |-- Trans_month: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- city_type: string (nullable = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StringType\n",
        "\n",
        "# Extract categorical columns (columns with string type)\n",
        "categorical_cols = [field.name for field in df_cleaned.schema.fields if isinstance(field.dataType, StringType)]\n",
        "\n",
        "# Show the categorical columns\n",
        "print(categorical_cols)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z1Il3oguueI",
        "outputId": "3d1c884d-0129-4f41-9942-96eff738e1b2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['category', 'gender', 'is_fraud', 'year', 'Trans_month', 'city_type']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# List of columns to encode - Updated to 'Trans_month'\n",
        "cols = ['Trans_month']\n",
        "\n",
        "# Apply StringIndexer to each column in the list\n",
        "for col in cols:\n",
        "    indexer = StringIndexer(inputCol=col, outputCol=col + \"_index\")\n",
        "    df_cleaned = indexer.fit(df_cleaned).transform(df_cleaned)\n",
        "\n",
        "# Show the resulting DataFrame with encoded columns\n",
        "df_cleaned.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "1Ryikj4yvCPQ",
        "outputId": "22d4f473-b4fe-4705-fd49-cb2efb7ce725"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IllegalArgumentException",
          "evalue": "requirement failed: Output column Trans_month_index already exists.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-dc3d8d01af0a>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIndexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdf_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Show the resulting DataFrame with encoded columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Output column Trans_month_index already exists."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the resulting DataFrame with encoded columns\n",
        "df_cleaned.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls8xdrx1vkfn",
        "outputId": "5bde6e67-a990-4023-db27-5c541287a06d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---+------+--------+----------------------+-----------+---+---------+-----------------+\n",
            "|     category|amt|gender|is_fraud|distance_from_merchant|Trans_month|age|city_type|Trans_month_index|\n",
            "+-------------+---+------+--------+----------------------+-----------+---+---------+-----------------+\n",
            "|     misc_net|  4|     0|       0|                    78|          1| 36|    Rural|              5.0|\n",
            "|  grocery_pos|107|     0|       0|                    30|          1| 46|    Rural|              5.0|\n",
            "|entertainment|220|     1|       0|                   108|          1| 62|    Rural|              5.0|\n",
            "|gas_transport| 45|     1|       0|                    95|          1| 57|    Rural|              5.0|\n",
            "|     misc_pos| 41|     1|       0|                    77|          1| 38|    Rural|              5.0|\n",
            "|gas_transport| 94|     0|       0|                    85|          1| 63|    Rural|              5.0|\n",
            "|  grocery_net| 44|     0|       0|                   118|          1| 31|    Rural|              5.0|\n",
            "|gas_transport| 71|     1|       0|                    12|          1| 77|    Rural|              5.0|\n",
            "|     misc_pos|  4|     0|       0|                    25|          1| 83|    Rural|              5.0|\n",
            "|  grocery_pos|198|     0|       0|                    74|          1| 50|    Rural|              5.0|\n",
            "|  grocery_pos| 24|     1|       0|                    97|          1| 34|    Rural|              5.0|\n",
            "| shopping_net|  7|     0|       0|                   106|          1| 58|    Rural|              5.0|\n",
            "|  grocery_pos| 71|     1|       0|                    44|          1| 35|    Rural|              5.0|\n",
            "|  grocery_pos| 96|     1|       0|                    25|          1| 79|    Rural|              5.0|\n",
            "| shopping_pos|  7|     1|       0|                    66|          1| 57|    Rural|              5.0|\n",
            "| shopping_net|  3|     1|       0|                    97|          1| 59|    Rural|              5.0|\n",
            "|     misc_net|327|     0|       0|                    87|          1| 72|    Rural|              5.0|\n",
            "| shopping_pos|341|     1|       0|                    87|          1| 86|    Rural|              5.0|\n",
            "|  food_dining| 63|     1|       0|                    90|          1| 78|    Rural|              5.0|\n",
            "|  grocery_pos| 44|     1|       0|                    84|          1| 44|    Rural|              5.0|\n",
            "+-------------+---+------+--------+----------------------+-----------+---+---------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Assuming df_cleaned is your DataFrame\n",
        "\n",
        "# 1. Identify non-ordinal categorical columns (e.g., 'category')\n",
        "non_ordinal_cols = ['category']\n",
        "\n",
        "# 2. Apply One-Hot Encoding to non-ordinal categorical columns\n",
        "indexers = []\n",
        "encoders = []\n",
        "\n",
        "for col in non_ordinal_cols:\n",
        "    # StringIndexer to convert the categorical column to a numeric index\n",
        "    indexer = StringIndexer(inputCol=col, outputCol=col + '_index')\n",
        "\n",
        "    # OneHotEncoder to convert the indexed column to one-hot encoding\n",
        "    encoder = OneHotEncoder(inputCol=col + '_index', outputCol=col + '_onehot')\n",
        "\n",
        "    indexers.append(indexer)\n",
        "    encoders.append(encoder)\n",
        "\n",
        "# 3. Build a pipeline to apply both StringIndexer and OneHotEncoder\n",
        "pipeline = Pipeline(stages=indexers + encoders)\n",
        "\n",
        "# Fit and transform the pipeline on the data\n",
        "df_transformed = pipeline.fit(df_cleaned).transform(df_cleaned)\n",
        "\n",
        "# 4. Convert boolean columns to integers (True/False to 1/0)\n",
        "# Assuming boolean columns are in boolean format, cast them to integers\n",
        "boolean_cols = [col for col in df_cleaned.columns if isinstance(df_cleaned.select(col).head()[0], bool)]\n",
        "\n",
        "for col in boolean_cols:\n",
        "    df_transformed = df_transformed.withColumn(col, F.col(col).cast('integer'))\n",
        "\n",
        "# Show the schema to confirm the changes\n",
        "df_transformed.printSchema()\n",
        "\n",
        "# Optionally, show the first few rows of the transformed DataFrame\n",
        "df_transformed.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69lDMC0EwFhS",
        "outputId": "645a6ed2-1293-47a2-9de5-6fd1c15e5a1e"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- category: string (nullable = true)\n",
            " |-- amt: integer (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- is_fraud: string (nullable = true)\n",
            " |-- distance_from_merchant: integer (nullable = true)\n",
            " |-- Trans_month: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- city_type: string (nullable = false)\n",
            " |-- Trans_month_index: double (nullable = false)\n",
            " |-- category_index: double (nullable = false)\n",
            " |-- category_onehot: vector (nullable = true)\n",
            "\n",
            "+-------------+---+------+--------+----------------------+-----------+---+---------+-----------------+--------------+---------------+\n",
            "|     category|amt|gender|is_fraud|distance_from_merchant|Trans_month|age|city_type|Trans_month_index|category_index|category_onehot|\n",
            "+-------------+---+------+--------+----------------------+-----------+---+---------+-----------------+--------------+---------------+\n",
            "|     misc_net|  4|     0|       0|                    78|          1| 36|    Rural|              5.0|          11.0|(13,[11],[1.0])|\n",
            "|  grocery_pos|107|     0|       0|                    30|          1| 46|    Rural|              5.0|           1.0| (13,[1],[1.0])|\n",
            "|entertainment|220|     1|       0|                   108|          1| 62|    Rural|              5.0|           6.0| (13,[6],[1.0])|\n",
            "|gas_transport| 45|     1|       0|                    95|          1| 57|    Rural|              5.0|           0.0| (13,[0],[1.0])|\n",
            "|     misc_pos| 41|     1|       0|                    77|          1| 38|    Rural|              5.0|          10.0|(13,[10],[1.0])|\n",
            "+-------------+---+------+--------+----------------------+-----------+---+---------+-----------------+--------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"FraudDetection\").getOrCreate()\n",
        "\n",
        "# Assuming 'df_cleaned' is already a PySpark DataFrame\n",
        "# If df_cleaned is a pandas DataFrame, you can convert it using:\n",
        "# df_cleaned = spark.createDataFrame(df_cleaned)\n",
        "\n",
        "# Step 1: Assemble features into a single vector column (excluding 'is_fraud')\n",
        "feature_columns = [col for col in df_cleaned.columns if col not in ['is_fraud', 'gender', 'city_type', 'category', 'category_onehot']]\n",
        "\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "df_assembled = assembler.transform(df_cleaned)\n",
        "\n",
        "# Step 2: Split the data into train and test sets (80% train, 20% test)\n",
        "train_df, test_df = df_assembled.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Step 3: Standardize the features using StandardScaler\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
        "scaler_model = scaler.fit(train_df)\n",
        "train_df_scaled = scaler_model.transform(train_df)\n",
        "test_df_scaled = scaler_model.transform(test_df)\n",
        "\n",
        "# Step 4: Prepare the data for training\n",
        "train_data = train_df_scaled.select('scaled_features', 'is_fraud').withColumnRenamed(\"scaled_features\", \"features\")\n",
        "test_data = test_df_scaled.select('scaled_features', 'is_fraud').withColumnRenamed(\"scaled_features\", \"features\")\n",
        "\n",
        "# Check the shapes of the training and test datasets\n",
        "print(\"Training features shape : \", train_data.count(), len(feature_columns))\n",
        "print(\"Test features shape : \", test_data.count(), len(feature_columns))\n",
        "print(\"Training target shape : \", train_data.count())\n",
        "print(\"Test target shape : \", test_data.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "iAs1kPYWwrcl",
        "outputId": "dc0ea987-c6a9-4eb7-da1b-89ccaafe15d1"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IllegalArgumentException",
          "evalue": "Data type string of column Trans_month is not supported.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-db9e1f6cb215>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0massembler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorAssembler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdf_assembled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massembler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Step 2: Split the data into train and test sets (80% train, 20% test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m: Data type string of column Trans_month is not supported."
          ]
        }
      ]
    }
  ]
}