{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPblU1BVcxQHmgHbdfMFHij",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/git-shashank-hp/Structured-ML-Credit-Card-Fraud-Detection-Project/blob/main/code_in_pyspark_ML_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZJhLv0_mlk23"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import feature\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Spark ML Example\") \\\n",
        "    .getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBfulXWYlmGq",
        "outputId": "87e8b403-3afe-4d9b-c6ee-d804bdf2bf47"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/gdrive/MyDrive/Colab Notebooks/CCDP/fraudTrain.csv'"
      ],
      "metadata": {
        "id": "TY8HZ5xIluzM"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading CSV data into a Spark DataFrame\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Show first few rows of data\n",
        "df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvHqUM5pl1q5",
        "outputId": "809ec291-3206-42c5-cf0a-1dab05b52e06"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------------------+----------------+--------------------+-------------+------+---------+-------+------+--------------------+--------------+-----+-----+-------+---------+--------+--------------------+----------+--------------------+----------+------------------+-----------+--------+\n",
            "|_c0|trans_date_trans_time|          cc_num|            merchant|     category|   amt|    first|   last|gender|              street|          city|state|  zip|    lat|     long|city_pop|                 job|       dob|           trans_num| unix_time|         merch_lat| merch_long|is_fraud|\n",
            "+---+---------------------+----------------+--------------------+-------------+------+---------+-------+------+--------------------+--------------+-----+-----+-------+---------+--------+--------------------+----------+--------------------+----------+------------------+-----------+--------+\n",
            "|  0|  2019-01-01 00:00:18|2703186189652095|fraud_Rippin, Kub...|     misc_net|  4.97| Jennifer|  Banks|     F|      561 Perry Cove|Moravian Falls|   NC|28654|36.0788| -81.1781|    3495|Psychologist, cou...|1988-03-09|0b242abb623afc578...|1325376018|         36.011293| -82.048315|       0|\n",
            "|  1|  2019-01-01 00:00:44|    630423337322|fraud_Heller, Gut...|  grocery_pos|107.23|Stephanie|   Gill|     F|43039 Riley Green...|        Orient|   WA|99160|48.8878|-118.2105|     149|Special education...|1978-06-21|1f76529f857473494...|1325376044|49.159046999999994|-118.186462|       0|\n",
            "|  2|  2019-01-01 00:00:51|  38859492057661|fraud_Lind-Buckridge|entertainment|220.11|   Edward|Sanchez|     M|594 White Dale Su...|    Malad City|   ID|83252|42.1808| -112.262|    4154|Nature conservati...|1962-01-19|a1a22d70485983eac...|1325376051|         43.150704|-112.154481|       0|\n",
            "|  3|  2019-01-01 00:01:16|3534093764340240|fraud_Kutch, Herm...|gas_transport|  45.0|   Jeremy|  White|     M|9443 Cynthia Cour...|       Boulder|   MT|59632|46.2306|-112.1138|    1939|     Patent attorney|1967-01-12|6b849c168bdad6f86...|1325376076|         47.034331|-112.561071|       0|\n",
            "|  4|  2019-01-01 00:03:06| 375534208663984| fraud_Keeling-Crist|     misc_pos| 41.96|    Tyler| Garcia|     M|    408 Bradley Rest|      Doe Hill|   VA|24433|38.4207| -79.4629|      99|Dance movement ps...|1986-03-28|a41d7549acf907893...|1325376186|         38.674999| -78.632459|       0|\n",
            "+---+---------------------+----------------+--------------------+-------------+------+---------+-------+------+--------------------+--------------+-----+-----+-------+---------+--------+--------------------+----------+--------------------+----------+------------------+-----------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print schema to see column names and types\n",
        "df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8Zvj-MGl9fd",
        "outputId": "a9f7010b-4801-468b-c02a-b180b6522985"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- trans_date_trans_time: timestamp (nullable = true)\n",
            " |-- cc_num: long (nullable = true)\n",
            " |-- merchant: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- amt: double (nullable = true)\n",
            " |-- first: string (nullable = true)\n",
            " |-- last: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- street: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- zip: integer (nullable = true)\n",
            " |-- lat: double (nullable = true)\n",
            " |-- long: double (nullable = true)\n",
            " |-- city_pop: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- dob: date (nullable = true)\n",
            " |-- trans_num: string (nullable = true)\n",
            " |-- unix_time: integer (nullable = true)\n",
            " |-- merch_lat: double (nullable = true)\n",
            " |-- merch_long: double (nullable = true)\n",
            " |-- is_fraud: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row_count = df.count()\n",
        "print(f\"Number of rows: {row_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ktoZeLqmPTI",
        "outputId": "0d372c29-dbb3-4fec-f2fd-cb3843fbbb00"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows: 1296675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZNE8uxBmgA2",
        "outputId": "4ceceabe-0315-4c7d-fb93-98493ba97bf8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"HaversineExample\").getOrCreate()\n",
        "\n",
        "# Haversine formula function to calculate distance between two latitudes and longitudes (in kilometers)\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    # Radius of the Earth in kilometers\n",
        "    R = 6371.0\n",
        "\n",
        "    # Convert degrees to radians\n",
        "    lat1_rad = math.radians(lat1)\n",
        "    lon1_rad = math.radians(lon1)\n",
        "    lat2_rad = math.radians(lat2)\n",
        "    lon2_rad = math.radians(lon2)\n",
        "\n",
        "    # Difference in coordinates\n",
        "    dlat = lat2_rad - lat1_rad\n",
        "    dlon = lon2_rad - lon1_rad\n",
        "\n",
        "    # Haversine formula\n",
        "    a = math.sin(dlat / 2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2)**2\n",
        "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
        "\n",
        "    # Distance in kilometers\n",
        "    distance = R * c\n",
        "    return distance\n",
        "\n",
        "# Register the Haversine function as a UDF (User Defined Function)\n",
        "haversine_udf = udf(haversine, DoubleType())\n",
        "\n",
        "# Assuming you have already loaded the dataset `df`\n",
        "# If you have more columns, let's make sure that we keep them all\n",
        "\n",
        "# Example to load your dataset into DataFrame (replace 'file_path' with the actual path)\n",
        "# Reading CSV data into a Spark DataFrame\n",
        "df1 = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Apply the Haversine UDF to calculate the distance and keep all original columns\n",
        "df_with_distance = df1.withColumn(\"distance_from_merchant\",\n",
        "                                 haversine_udf(\"lat\", \"long\", \"merch_lat\", \"merch_long\"))\n",
        "\n",
        "# Show the resulting DataFrame with the calculated distance, along with all original columns\n",
        "df_with_distance.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUqMkgn8ml2o",
        "outputId": "266fa595-032c-4db5-ec61-f2aff0ee80a5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------------------+-------------------+----------------------------------------+-------------+------+-----------+---------+------+------------------------------+------------------------+-----+-----+-------+------------------+--------+---------------------------------------------+----------+--------------------------------+----------+------------------+------------------+--------+----------------------+\n",
            "|_c0|trans_date_trans_time|cc_num             |merchant                                |category     |amt   |first      |last     |gender|street                        |city                    |state|zip  |lat    |long              |city_pop|job                                          |dob       |trans_num                       |unix_time |merch_lat         |merch_long        |is_fraud|distance_from_merchant|\n",
            "+---+---------------------+-------------------+----------------------------------------+-------------+------+-----------+---------+------+------------------------------+------------------------+-----+-----+-------+------------------+--------+---------------------------------------------+----------+--------------------------------+----------+------------------+------------------+--------+----------------------+\n",
            "|0  |2019-01-01 00:00:18  |2703186189652095   |fraud_Rippin, Kub and Mann              |misc_net     |4.97  |Jennifer   |Banks    |F     |561 Perry Cove                |Moravian Falls          |NC   |28654|36.0788|-81.1781          |3495    |Psychologist, counselling                    |1988-03-09|0b242abb623afc578575680df30655b9|1325376018|36.011293         |-82.048315        |0       |78.59756848823062     |\n",
            "|1  |2019-01-01 00:00:44  |630423337322       |fraud_Heller, Gutmann and Zieme         |grocery_pos  |107.23|Stephanie  |Gill     |F     |43039 Riley Greens Suite 393  |Orient                  |WA   |99160|48.8878|-118.2105         |149     |Special educational needs teacher            |1978-06-21|1f76529f8574734946361c461b024d99|1325376044|49.159046999999994|-118.186462       |0       |30.212175719210443    |\n",
            "|2  |2019-01-01 00:00:51  |38859492057661     |fraud_Lind-Buckridge                    |entertainment|220.11|Edward     |Sanchez  |M     |594 White Dale Suite 530      |Malad City              |ID   |83252|42.1808|-112.262          |4154    |Nature conservation officer                  |1962-01-19|a1a22d70485983eac12b5b88dad1cf95|1325376051|43.150704         |-112.154481       |0       |108.20608258720067    |\n",
            "|3  |2019-01-01 00:01:16  |3534093764340240   |fraud_Kutch, Hermiston and Farrell      |gas_transport|45.0  |Jeremy     |White    |M     |9443 Cynthia Court Apt. 038   |Boulder                 |MT   |59632|46.2306|-112.1138         |1939    |Patent attorney                              |1967-01-12|6b849c168bdad6f867558c3793159a81|1325376076|47.034331         |-112.561071       |0       |95.67323113819748     |\n",
            "|4  |2019-01-01 00:03:06  |375534208663984    |fraud_Keeling-Crist                     |misc_pos     |41.96 |Tyler      |Garcia   |M     |408 Bradley Rest              |Doe Hill                |VA   |24433|38.4207|-79.4629          |99      |Dance movement psychotherapist               |1986-03-28|a41d7549acf90789359a9aa5346dcb46|1325376186|38.674999         |-78.632459        |0       |77.5567436258178      |\n",
            "|5  |2019-01-01 00:04:08  |4767265376804500   |fraud_Stroman, Hudson and Erdman        |gas_transport|94.63 |Jennifer   |Conner   |F     |4655 David Island             |Dublin                  |PA   |18917|40.375 |-75.2045          |2158    |Transport planner                            |1961-06-19|189a841a0a8ba03058526bcfe566aab5|1325376248|40.653382         |-76.15266700000001|0       |85.92264266264023     |\n",
            "|6  |2019-01-01 00:04:42  |30074693890476     |fraud_Rowe-Vandervort                   |grocery_net  |44.54 |Kelsey     |Richards |F     |889 Sarah Station Suite 624   |Holcomb                 |KS   |67851|37.9931|-100.9893         |2691    |Arboriculturist                              |1993-08-16|83ec1cc84142af6e2acf10c44949e720|1325376282|37.162704999999995|-100.15337        |0       |118.11977555909641    |\n",
            "|7  |2019-01-01 00:05:08  |6011360759745864   |fraud_Corwin-Collins                    |gas_transport|71.65 |Steven     |Williams |M     |231 Flores Pass Suite 720     |Edinburg                |VA   |22824|38.8432|-78.6003          |6018    |Designer, multimedia                         |1947-08-21|6d294ed2cc447d2c71c7171a3d54967c|1325376308|38.948089         |-78.540296        |0       |12.766922541959126    |\n",
            "|8  |2019-01-01 00:05:18  |4922710831011201   |fraud_Herzog Ltd                        |misc_pos     |4.27  |Heather    |Chase    |F     |6888 Hicks Stream Suite 954   |Manor                   |PA   |15665|40.3359|-79.6607          |1472    |Public affairs consultant                    |1941-03-07|fc28024ce480f8ef21a32d64c93a29f5|1325376318|40.351813         |-79.958146        |0       |25.27049367104955     |\n",
            "|9  |2019-01-01 00:06:01  |2720830304681674   |fraud_Schoen, Kuphal and Nitzsche       |grocery_pos  |198.39|Melissa    |Aguilar  |F     |21326 Taylor Squares Suite 708|Clarksville             |TN   |37040|36.522 |-87.34899999999999|151785  |Pathologist                                  |1974-03-28|3b9014ea8fb80bd65de0b1463b00b00e|1325376361|37.179198         |-87.485381        |0       |74.07775048182131     |\n",
            "|10 |2019-01-01 00:06:23  |4642894980163      |fraud_Rutherford-Mertz                  |grocery_pos  |24.74 |Eddie      |Mendez   |M     |1831 Faith View Suite 653     |Clarinda                |IA   |51632|40.7491|-95.038           |7297    |IT trainer                                   |1990-07-13|d71c95ab6b7356dd74389d41df429c87|1325376383|40.275890999999994|-96.011548        |0       |97.68326577207269     |\n",
            "|11 |2019-01-01 00:06:53  |377234009633447    |fraud_Kerluke-Abshire                   |shopping_net |7.77  |Theresa    |Blackwell|F     |43576 Kristina Islands        |Shenandoah Junction     |WV   |25442|39.3716|-77.8229          |1925    |Systems developer                            |1966-02-14|3c74776e558f1499a7824b556e474b1d|1325376413|40.103866         |-78.624459        |0       |106.4293808943283     |\n",
            "|12 |2019-01-01 00:06:56  |180042946491150    |fraud_Lockman Ltd                       |grocery_pos  |71.22 |Charles    |Robles   |M     |3337 Lisa Divide              |Saint Petersburg        |FL   |33710|27.7898|-82.7243          |341043  |Engineer, land                               |1989-02-28|c1d9a7ddb1e34639fe82758de97f4abf|1325376416|27.630593         |-82.308891        |0       |44.56107983071174     |\n",
            "|13 |2019-01-01 00:07:27  |5559857416065248   |fraud_Kiehn Inc                         |grocery_pos  |96.29 |Jack       |Hill     |M     |5916 Susan Bridge Apt. 939    |Grenada                 |CA   |96038|41.6125|-122.5258         |589     |Systems analyst                              |1945-12-21|413636e759663f264aae1819a4d4f231|1325376447|41.65752          |-122.230347       |0       |25.059079169313318    |\n",
            "|14 |2019-01-01 00:09:03  |3514865930894695   |fraud_Beier-Hyatt                       |shopping_pos |7.77  |Christopher|Castaneda|M     |1632 Cohen Drive Suite 639    |High Rolls Mountain Park|NM   |88325|32.9396|-105.8189         |899     |Naval architect                              |1967-08-30|8a6293af5ed278dea14448ded2685fea|1325376543|32.863258         |-106.520205       |0       |66.02168481006179     |\n",
            "|15 |2019-01-01 00:09:20  |6011999606625827   |fraud_Schmidt and Sons                  |shopping_net |3.26  |Ronald     |Carson   |M     |870 Rocha Drive               |Harrington Park         |NJ   |7640 |40.9918|-73.98            |4664    |Radiographer, diagnostic                     |1965-06-30|baae0b096835c975857eea7e28dde3dc|1325376560|41.831174         |-74.335559        |0       |97.93065268602581     |\n",
            "|16 |2019-01-01 00:10:49  |6011860238257910   |fraud_Lebsack and Sons                  |misc_net     |327.0 |Lisa       |Mendez   |F     |44259 Beth Station Suite 215  |Lahoma                  |OK   |73754|36.385 |-98.0727          |1078    |Programme researcher, broadcasting/film/video|1952-07-06|991c04803b4d4eeab30d6245a872e3d3|1325376649|36.384091999999995|-99.048472        |0       |87.34874840731703     |\n",
            "|17 |2019-01-01 00:10:58  |3565423334076143   |fraud_Mayert Group                      |shopping_pos |341.67|Nathan     |Thomas   |M     |4923 Campbell Pines Suite 717 |Carlisle                |IN   |47838|38.9763|-87.3667          |4081    |Energy engineer                              |1938-03-15|f12cf52be2175703db789a4644c32f25|1325376658|38.674490999999996|-88.305767        |0       |87.99895015911639     |\n",
            "|18 |2019-01-01 00:11:14  |2348245054386329   |fraud_Konopelski, Schneider and Hartmann|food_dining  |63.07 |Justin     |Gay      |M     |268 Hayes Rue Suite 811       |Harborcreek             |PA   |16421|42.1767|-79.9416          |2518    |Event organiser                              |1946-02-02|8500f3d459047eac8443307b1e8296e5|1325376674|41.430274         |-79.492553        |0       |90.96220878947973     |\n",
            "|19 |2019-01-01 00:12:34  |4956828990005111019|fraud_Schultz, Simonis and Little       |grocery_pos  |44.71 |Kenneth    |Robinson |M     |269 Sanchez Rapids            |Elizabeth               |NJ   |7208 |40.6747|-74.2239          |124967  |Operational researcher                       |1980-12-21|09eff9c806365e2a6be12c1bbab3d70e|1325376754|40.079588         |-74.84808699999999|0       |84.70212030854243     |\n",
            "+---+---------------------+-------------------+----------------------------------------+-------------+------+-----------+---------+------+------------------------------+------------------------+-----+-----+-------+------------------+--------+---------------------------------------------+----------+--------------------------------+----------+------------------+------------------+--------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print schema to see column names and types\n",
        "df_with_distance.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V8ke2z6nIGV",
        "outputId": "add71577-a011-4489-bee4-0d0e3a43edfa"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- trans_date_trans_time: timestamp (nullable = true)\n",
            " |-- cc_num: long (nullable = true)\n",
            " |-- merchant: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- amt: double (nullable = true)\n",
            " |-- first: string (nullable = true)\n",
            " |-- last: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- street: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- zip: integer (nullable = true)\n",
            " |-- lat: double (nullable = true)\n",
            " |-- long: double (nullable = true)\n",
            " |-- city_pop: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- dob: date (nullable = true)\n",
            " |-- trans_num: string (nullable = true)\n",
            " |-- unix_time: integer (nullable = true)\n",
            " |-- merch_lat: double (nullable = true)\n",
            " |-- merch_long: double (nullable = true)\n",
            " |-- is_fraud: integer (nullable = true)\n",
            " |-- distance_from_merchant: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unwanted columns from df_with_distance\n",
        "df_cleaned = df_with_distance.drop('_c0', 'merchant', 'cc_num', 'first',\n",
        "                                   'state', 'last', 'trans_num', 'unix_time',\n",
        "                                   'street', 'city', 'lat', 'long', 'merch_lat',\n",
        "                                   'merch_long', 'zip')\n",
        "\n",
        "# Show the cleaned DataFrame with the remaining columns\n",
        "df_cleaned.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0UTbjL3neBl",
        "outputId": "52542baf-c374-4fce-8756-255e86c501ba"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+-------------+------+------+--------+---------------------------------------------+----------+--------+----------------------+\n",
            "|trans_date_trans_time|category     |amt   |gender|city_pop|job                                          |dob       |is_fraud|distance_from_merchant|\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+----------+--------+----------------------+\n",
            "|2019-01-01 00:00:18  |misc_net     |4.97  |F     |3495    |Psychologist, counselling                    |1988-03-09|0       |78.59756848823062     |\n",
            "|2019-01-01 00:00:44  |grocery_pos  |107.23|F     |149     |Special educational needs teacher            |1978-06-21|0       |30.212175719210443    |\n",
            "|2019-01-01 00:00:51  |entertainment|220.11|M     |4154    |Nature conservation officer                  |1962-01-19|0       |108.20608258720067    |\n",
            "|2019-01-01 00:01:16  |gas_transport|45.0  |M     |1939    |Patent attorney                              |1967-01-12|0       |95.67323113819748     |\n",
            "|2019-01-01 00:03:06  |misc_pos     |41.96 |M     |99      |Dance movement psychotherapist               |1986-03-28|0       |77.5567436258178      |\n",
            "|2019-01-01 00:04:08  |gas_transport|94.63 |F     |2158    |Transport planner                            |1961-06-19|0       |85.92264266264023     |\n",
            "|2019-01-01 00:04:42  |grocery_net  |44.54 |F     |2691    |Arboriculturist                              |1993-08-16|0       |118.11977555909641    |\n",
            "|2019-01-01 00:05:08  |gas_transport|71.65 |M     |6018    |Designer, multimedia                         |1947-08-21|0       |12.766922541959126    |\n",
            "|2019-01-01 00:05:18  |misc_pos     |4.27  |F     |1472    |Public affairs consultant                    |1941-03-07|0       |25.27049367104955     |\n",
            "|2019-01-01 00:06:01  |grocery_pos  |198.39|F     |151785  |Pathologist                                  |1974-03-28|0       |74.07775048182131     |\n",
            "|2019-01-01 00:06:23  |grocery_pos  |24.74 |M     |7297    |IT trainer                                   |1990-07-13|0       |97.68326577207269     |\n",
            "|2019-01-01 00:06:53  |shopping_net |7.77  |F     |1925    |Systems developer                            |1966-02-14|0       |106.4293808943283     |\n",
            "|2019-01-01 00:06:56  |grocery_pos  |71.22 |M     |341043  |Engineer, land                               |1989-02-28|0       |44.56107983071174     |\n",
            "|2019-01-01 00:07:27  |grocery_pos  |96.29 |M     |589     |Systems analyst                              |1945-12-21|0       |25.059079169313318    |\n",
            "|2019-01-01 00:09:03  |shopping_pos |7.77  |M     |899     |Naval architect                              |1967-08-30|0       |66.02168481006179     |\n",
            "|2019-01-01 00:09:20  |shopping_net |3.26  |M     |4664    |Radiographer, diagnostic                     |1965-06-30|0       |97.93065268602581     |\n",
            "|2019-01-01 00:10:49  |misc_net     |327.0 |F     |1078    |Programme researcher, broadcasting/film/video|1952-07-06|0       |87.34874840731703     |\n",
            "|2019-01-01 00:10:58  |shopping_pos |341.67|M     |4081    |Energy engineer                              |1938-03-15|0       |87.99895015911639     |\n",
            "|2019-01-01 00:11:14  |food_dining  |63.07 |M     |2518    |Event organiser                              |1946-02-02|0       |90.96220878947973     |\n",
            "|2019-01-01 00:12:34  |grocery_pos  |44.71 |M     |124967  |Operational researcher                       |1980-12-21|0       |84.70212030854243     |\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+----------+--------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import to_timestamp\n",
        "\n",
        "# Convert 'trans_date_trans_time' to timestamp\n",
        "df_cleaned = df_cleaned.withColumn('trans_date_trans_time', to_timestamp('trans_date_trans_time'))\n",
        "\n",
        "# Convert 'dob' to timestamp\n",
        "df_cleaned = df_cleaned.withColumn('dob', to_timestamp('dob'))\n",
        "\n",
        "# Show the updated DataFrame schema to verify the changes\n",
        "df_cleaned.printSchema()\n",
        "\n",
        "# Show the DataFrame to verify the conversions\n",
        "df_cleaned.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIYdA4ibpsrm",
        "outputId": "f5172eb1-d492-42f5-f5f6-21c4e7f50c7c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- trans_date_trans_time: timestamp (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- amt: double (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- city_pop: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- dob: timestamp (nullable = true)\n",
            " |-- is_fraud: integer (nullable = true)\n",
            " |-- distance_from_merchant: double (nullable = true)\n",
            "\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+-------------------+--------+----------------------+\n",
            "|trans_date_trans_time|category     |amt   |gender|city_pop|job                                          |dob                |is_fraud|distance_from_merchant|\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+-------------------+--------+----------------------+\n",
            "|2019-01-01 00:00:18  |misc_net     |4.97  |F     |3495    |Psychologist, counselling                    |1988-03-09 00:00:00|0       |78.59756848823062     |\n",
            "|2019-01-01 00:00:44  |grocery_pos  |107.23|F     |149     |Special educational needs teacher            |1978-06-21 00:00:00|0       |30.212175719210443    |\n",
            "|2019-01-01 00:00:51  |entertainment|220.11|M     |4154    |Nature conservation officer                  |1962-01-19 00:00:00|0       |108.20608258720067    |\n",
            "|2019-01-01 00:01:16  |gas_transport|45.0  |M     |1939    |Patent attorney                              |1967-01-12 00:00:00|0       |95.67323113819748     |\n",
            "|2019-01-01 00:03:06  |misc_pos     |41.96 |M     |99      |Dance movement psychotherapist               |1986-03-28 00:00:00|0       |77.5567436258178      |\n",
            "|2019-01-01 00:04:08  |gas_transport|94.63 |F     |2158    |Transport planner                            |1961-06-19 00:00:00|0       |85.92264266264023     |\n",
            "|2019-01-01 00:04:42  |grocery_net  |44.54 |F     |2691    |Arboriculturist                              |1993-08-16 00:00:00|0       |118.11977555909641    |\n",
            "|2019-01-01 00:05:08  |gas_transport|71.65 |M     |6018    |Designer, multimedia                         |1947-08-21 00:00:00|0       |12.766922541959126    |\n",
            "|2019-01-01 00:05:18  |misc_pos     |4.27  |F     |1472    |Public affairs consultant                    |1941-03-07 00:00:00|0       |25.27049367104955     |\n",
            "|2019-01-01 00:06:01  |grocery_pos  |198.39|F     |151785  |Pathologist                                  |1974-03-28 00:00:00|0       |74.07775048182131     |\n",
            "|2019-01-01 00:06:23  |grocery_pos  |24.74 |M     |7297    |IT trainer                                   |1990-07-13 00:00:00|0       |97.68326577207269     |\n",
            "|2019-01-01 00:06:53  |shopping_net |7.77  |F     |1925    |Systems developer                            |1966-02-14 00:00:00|0       |106.4293808943283     |\n",
            "|2019-01-01 00:06:56  |grocery_pos  |71.22 |M     |341043  |Engineer, land                               |1989-02-28 00:00:00|0       |44.56107983071174     |\n",
            "|2019-01-01 00:07:27  |grocery_pos  |96.29 |M     |589     |Systems analyst                              |1945-12-21 00:00:00|0       |25.059079169313318    |\n",
            "|2019-01-01 00:09:03  |shopping_pos |7.77  |M     |899     |Naval architect                              |1967-08-30 00:00:00|0       |66.02168481006179     |\n",
            "|2019-01-01 00:09:20  |shopping_net |3.26  |M     |4664    |Radiographer, diagnostic                     |1965-06-30 00:00:00|0       |97.93065268602581     |\n",
            "|2019-01-01 00:10:49  |misc_net     |327.0 |F     |1078    |Programme researcher, broadcasting/film/video|1952-07-06 00:00:00|0       |87.34874840731703     |\n",
            "|2019-01-01 00:10:58  |shopping_pos |341.67|M     |4081    |Energy engineer                              |1938-03-15 00:00:00|0       |87.99895015911639     |\n",
            "|2019-01-01 00:11:14  |food_dining  |63.07 |M     |2518    |Event organiser                              |1946-02-02 00:00:00|0       |90.96220878947973     |\n",
            "|2019-01-01 00:12:34  |grocery_pos  |44.71 |M     |124967  |Operational researcher                       |1980-12-21 00:00:00|0       |84.70212030854243     |\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+-------------------+--------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import year, month, dayofmonth, current_date\n",
        "\n",
        "# Extract individual date-time components from 'trans_date_trans_time'\n",
        "df_cleaned = df_cleaned.withColumn('year', year('trans_date_trans_time'))\n",
        "df_cleaned = df_cleaned.withColumn('Trans_month', month('trans_date_trans_time'))\n",
        "\n",
        "# Extract individual date-time components from 'dob'\n",
        "df_cleaned = df_cleaned.withColumn('birth_year', year('dob'))\n",
        "\n",
        "# Calculate age by subtracting birth year from the current year\n",
        "current_year = current_date().substr(1, 4).cast('int')  # Extract current year as integer\n",
        "df_cleaned = df_cleaned.withColumn('age', current_year - df_cleaned['birth_year'])\n",
        "\n",
        "# Show the updated DataFrame with the new columns\n",
        "df_cleaned.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qoxy8l0lp0Hf",
        "outputId": "629e034a-e108-4249-f556-4417f4388b6c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+-------------+------+------+--------+---------------------------------------------+-------------------+--------+----------------------+----+-----------+----------+---+\n",
            "|trans_date_trans_time|category     |amt   |gender|city_pop|job                                          |dob                |is_fraud|distance_from_merchant|year|Trans_month|birth_year|age|\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+-------------------+--------+----------------------+----+-----------+----------+---+\n",
            "|2019-01-01 00:00:18  |misc_net     |4.97  |F     |3495    |Psychologist, counselling                    |1988-03-09 00:00:00|0       |78.59756848823062     |2019|1          |1988      |36 |\n",
            "|2019-01-01 00:00:44  |grocery_pos  |107.23|F     |149     |Special educational needs teacher            |1978-06-21 00:00:00|0       |30.212175719210443    |2019|1          |1978      |46 |\n",
            "|2019-01-01 00:00:51  |entertainment|220.11|M     |4154    |Nature conservation officer                  |1962-01-19 00:00:00|0       |108.20608258720067    |2019|1          |1962      |62 |\n",
            "|2019-01-01 00:01:16  |gas_transport|45.0  |M     |1939    |Patent attorney                              |1967-01-12 00:00:00|0       |95.67323113819748     |2019|1          |1967      |57 |\n",
            "|2019-01-01 00:03:06  |misc_pos     |41.96 |M     |99      |Dance movement psychotherapist               |1986-03-28 00:00:00|0       |77.5567436258178      |2019|1          |1986      |38 |\n",
            "|2019-01-01 00:04:08  |gas_transport|94.63 |F     |2158    |Transport planner                            |1961-06-19 00:00:00|0       |85.92264266264023     |2019|1          |1961      |63 |\n",
            "|2019-01-01 00:04:42  |grocery_net  |44.54 |F     |2691    |Arboriculturist                              |1993-08-16 00:00:00|0       |118.11977555909641    |2019|1          |1993      |31 |\n",
            "|2019-01-01 00:05:08  |gas_transport|71.65 |M     |6018    |Designer, multimedia                         |1947-08-21 00:00:00|0       |12.766922541959126    |2019|1          |1947      |77 |\n",
            "|2019-01-01 00:05:18  |misc_pos     |4.27  |F     |1472    |Public affairs consultant                    |1941-03-07 00:00:00|0       |25.27049367104955     |2019|1          |1941      |83 |\n",
            "|2019-01-01 00:06:01  |grocery_pos  |198.39|F     |151785  |Pathologist                                  |1974-03-28 00:00:00|0       |74.07775048182131     |2019|1          |1974      |50 |\n",
            "|2019-01-01 00:06:23  |grocery_pos  |24.74 |M     |7297    |IT trainer                                   |1990-07-13 00:00:00|0       |97.68326577207269     |2019|1          |1990      |34 |\n",
            "|2019-01-01 00:06:53  |shopping_net |7.77  |F     |1925    |Systems developer                            |1966-02-14 00:00:00|0       |106.4293808943283     |2019|1          |1966      |58 |\n",
            "|2019-01-01 00:06:56  |grocery_pos  |71.22 |M     |341043  |Engineer, land                               |1989-02-28 00:00:00|0       |44.56107983071174     |2019|1          |1989      |35 |\n",
            "|2019-01-01 00:07:27  |grocery_pos  |96.29 |M     |589     |Systems analyst                              |1945-12-21 00:00:00|0       |25.059079169313318    |2019|1          |1945      |79 |\n",
            "|2019-01-01 00:09:03  |shopping_pos |7.77  |M     |899     |Naval architect                              |1967-08-30 00:00:00|0       |66.02168481006179     |2019|1          |1967      |57 |\n",
            "|2019-01-01 00:09:20  |shopping_net |3.26  |M     |4664    |Radiographer, diagnostic                     |1965-06-30 00:00:00|0       |97.93065268602581     |2019|1          |1965      |59 |\n",
            "|2019-01-01 00:10:49  |misc_net     |327.0 |F     |1078    |Programme researcher, broadcasting/film/video|1952-07-06 00:00:00|0       |87.34874840731703     |2019|1          |1952      |72 |\n",
            "|2019-01-01 00:10:58  |shopping_pos |341.67|M     |4081    |Energy engineer                              |1938-03-15 00:00:00|0       |87.99895015911639     |2019|1          |1938      |86 |\n",
            "|2019-01-01 00:11:14  |food_dining  |63.07 |M     |2518    |Event organiser                              |1946-02-02 00:00:00|0       |90.96220878947973     |2019|1          |1946      |78 |\n",
            "|2019-01-01 00:12:34  |grocery_pos  |44.71 |M     |124967  |Operational researcher                       |1980-12-21 00:00:00|0       |84.70212030854243     |2019|1          |1980      |44 |\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+-------------------+--------+----------------------+----+-----------+----------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Convert 'year' and 'Trans_month' columns to string (PySpark equivalent of 'object' in Pandas)\n",
        "df_cleaned = df_cleaned.withColumn('year', col('year').cast('string'))\n",
        "df_cleaned = df_cleaned.withColumn('Trans_month', col('Trans_month').cast('string'))\n",
        "\n",
        "# Show the updated DataFrame with the new column types\n",
        "df_cleaned.printSchema()\n",
        "df_cleaned.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0LqjAAaqLk8",
        "outputId": "b5b1f383-20d7-433e-a529-a6f0f649bbbc"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- trans_date_trans_time: timestamp (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- amt: double (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- city_pop: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- dob: timestamp (nullable = true)\n",
            " |-- is_fraud: integer (nullable = true)\n",
            " |-- distance_from_merchant: double (nullable = true)\n",
            " |-- year: string (nullable = true)\n",
            " |-- Trans_month: string (nullable = true)\n",
            " |-- birth_year: integer (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            "\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+-------------------+--------+----------------------+----+-----------+----------+---+\n",
            "|trans_date_trans_time|category     |amt   |gender|city_pop|job                                          |dob                |is_fraud|distance_from_merchant|year|Trans_month|birth_year|age|\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+-------------------+--------+----------------------+----+-----------+----------+---+\n",
            "|2019-01-01 00:00:18  |misc_net     |4.97  |F     |3495    |Psychologist, counselling                    |1988-03-09 00:00:00|0       |78.59756848823062     |2019|1          |1988      |36 |\n",
            "|2019-01-01 00:00:44  |grocery_pos  |107.23|F     |149     |Special educational needs teacher            |1978-06-21 00:00:00|0       |30.212175719210443    |2019|1          |1978      |46 |\n",
            "|2019-01-01 00:00:51  |entertainment|220.11|M     |4154    |Nature conservation officer                  |1962-01-19 00:00:00|0       |108.20608258720067    |2019|1          |1962      |62 |\n",
            "|2019-01-01 00:01:16  |gas_transport|45.0  |M     |1939    |Patent attorney                              |1967-01-12 00:00:00|0       |95.67323113819748     |2019|1          |1967      |57 |\n",
            "|2019-01-01 00:03:06  |misc_pos     |41.96 |M     |99      |Dance movement psychotherapist               |1986-03-28 00:00:00|0       |77.5567436258178      |2019|1          |1986      |38 |\n",
            "|2019-01-01 00:04:08  |gas_transport|94.63 |F     |2158    |Transport planner                            |1961-06-19 00:00:00|0       |85.92264266264023     |2019|1          |1961      |63 |\n",
            "|2019-01-01 00:04:42  |grocery_net  |44.54 |F     |2691    |Arboriculturist                              |1993-08-16 00:00:00|0       |118.11977555909641    |2019|1          |1993      |31 |\n",
            "|2019-01-01 00:05:08  |gas_transport|71.65 |M     |6018    |Designer, multimedia                         |1947-08-21 00:00:00|0       |12.766922541959126    |2019|1          |1947      |77 |\n",
            "|2019-01-01 00:05:18  |misc_pos     |4.27  |F     |1472    |Public affairs consultant                    |1941-03-07 00:00:00|0       |25.27049367104955     |2019|1          |1941      |83 |\n",
            "|2019-01-01 00:06:01  |grocery_pos  |198.39|F     |151785  |Pathologist                                  |1974-03-28 00:00:00|0       |74.07775048182131     |2019|1          |1974      |50 |\n",
            "|2019-01-01 00:06:23  |grocery_pos  |24.74 |M     |7297    |IT trainer                                   |1990-07-13 00:00:00|0       |97.68326577207269     |2019|1          |1990      |34 |\n",
            "|2019-01-01 00:06:53  |shopping_net |7.77  |F     |1925    |Systems developer                            |1966-02-14 00:00:00|0       |106.4293808943283     |2019|1          |1966      |58 |\n",
            "|2019-01-01 00:06:56  |grocery_pos  |71.22 |M     |341043  |Engineer, land                               |1989-02-28 00:00:00|0       |44.56107983071174     |2019|1          |1989      |35 |\n",
            "|2019-01-01 00:07:27  |grocery_pos  |96.29 |M     |589     |Systems analyst                              |1945-12-21 00:00:00|0       |25.059079169313318    |2019|1          |1945      |79 |\n",
            "|2019-01-01 00:09:03  |shopping_pos |7.77  |M     |899     |Naval architect                              |1967-08-30 00:00:00|0       |66.02168481006179     |2019|1          |1967      |57 |\n",
            "|2019-01-01 00:09:20  |shopping_net |3.26  |M     |4664    |Radiographer, diagnostic                     |1965-06-30 00:00:00|0       |97.93065268602581     |2019|1          |1965      |59 |\n",
            "|2019-01-01 00:10:49  |misc_net     |327.0 |F     |1078    |Programme researcher, broadcasting/film/video|1952-07-06 00:00:00|0       |87.34874840731703     |2019|1          |1952      |72 |\n",
            "|2019-01-01 00:10:58  |shopping_pos |341.67|M     |4081    |Energy engineer                              |1938-03-15 00:00:00|0       |87.99895015911639     |2019|1          |1938      |86 |\n",
            "|2019-01-01 00:11:14  |food_dining  |63.07 |M     |2518    |Event organiser                              |1946-02-02 00:00:00|0       |90.96220878947973     |2019|1          |1946      |78 |\n",
            "|2019-01-01 00:12:34  |grocery_pos  |44.71 |M     |124967  |Operational researcher                       |1980-12-21 00:00:00|0       |84.70212030854243     |2019|1          |1980      |44 |\n",
            "+---------------------+-------------+------+------+--------+---------------------------------------------+-------------------+--------+----------------------+----+-----------+----------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop specified columns from df_cleaned\n",
        "df_cleaned = df_cleaned.drop('trans_date_trans_time', 'birth_year', 'dob', 'job')\n",
        "\n",
        "# Show the cleaned DataFrame to verify the columns have been removed\n",
        "df_cleaned.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJKHUhY7qMTY",
        "outputId": "ec91888b-9cf9-4fdc-8123-503d6c32f288"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------+------+--------+--------+----------------------+----+-----------+---+\n",
            "|category     |amt   |gender|city_pop|is_fraud|distance_from_merchant|year|Trans_month|age|\n",
            "+-------------+------+------+--------+--------+----------------------+----+-----------+---+\n",
            "|misc_net     |4.97  |F     |3495    |0       |78.59756848823062     |2019|1          |36 |\n",
            "|grocery_pos  |107.23|F     |149     |0       |30.212175719210443    |2019|1          |46 |\n",
            "|entertainment|220.11|M     |4154    |0       |108.20608258720067    |2019|1          |62 |\n",
            "|gas_transport|45.0  |M     |1939    |0       |95.67323113819748     |2019|1          |57 |\n",
            "|misc_pos     |41.96 |M     |99      |0       |77.5567436258178      |2019|1          |38 |\n",
            "|gas_transport|94.63 |F     |2158    |0       |85.92264266264023     |2019|1          |63 |\n",
            "|grocery_net  |44.54 |F     |2691    |0       |118.11977555909641    |2019|1          |31 |\n",
            "|gas_transport|71.65 |M     |6018    |0       |12.766922541959126    |2019|1          |77 |\n",
            "|misc_pos     |4.27  |F     |1472    |0       |25.27049367104955     |2019|1          |83 |\n",
            "|grocery_pos  |198.39|F     |151785  |0       |74.07775048182131     |2019|1          |50 |\n",
            "|grocery_pos  |24.74 |M     |7297    |0       |97.68326577207269     |2019|1          |34 |\n",
            "|shopping_net |7.77  |F     |1925    |0       |106.4293808943283     |2019|1          |58 |\n",
            "|grocery_pos  |71.22 |M     |341043  |0       |44.56107983071174     |2019|1          |35 |\n",
            "|grocery_pos  |96.29 |M     |589     |0       |25.059079169313318    |2019|1          |79 |\n",
            "|shopping_pos |7.77  |M     |899     |0       |66.02168481006179     |2019|1          |57 |\n",
            "|shopping_net |3.26  |M     |4664    |0       |97.93065268602581     |2019|1          |59 |\n",
            "|misc_net     |327.0 |F     |1078    |0       |87.34874840731703     |2019|1          |72 |\n",
            "|shopping_pos |341.67|M     |4081    |0       |87.99895015911639     |2019|1          |86 |\n",
            "|food_dining  |63.07 |M     |2518    |0       |90.96220878947973     |2019|1          |78 |\n",
            "|grocery_pos  |44.71 |M     |124967  |0       |84.70212030854243     |2019|1          |44 |\n",
            "+-------------+------+------+--------+--------+----------------------+----+-----------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import max\n",
        "\n",
        "# Find the maximum value of 'city_pop' column\n",
        "max_city_pop = df_cleaned.agg(max('city_pop')).collect()[0][0]\n",
        "\n",
        "# Print the maximum value\n",
        "print(\"Maximum value of 'city_pop':\", max_city_pop)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl83bEubqZRi",
        "outputId": "3d3f57f5-3fea-45c2-dbdd-68562485f58b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum value of 'city_pop': 2906700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Define the population thresholds\n",
        "rural_threshold = 1000000  # Population < 1 million\n",
        "metropolitan_threshold = 5000000  # Population > 5 million\n",
        "\n",
        "# Create a new 'city_type' column based on population\n",
        "df_cleaned = df_cleaned.withColumn(\n",
        "    'city_type',\n",
        "    F.when(df_cleaned['city_pop'] < rural_threshold, 'rural')  # Cities with < 1M population\n",
        "     .when((df_cleaned['city_pop'] >= rural_threshold) & (df_cleaned['city_pop'] < metropolitan_threshold), 'subarban')  # Cities between 1M and 5M population\n",
        "     .otherwise('3 - metropolitan')  # Cities with > 5M population\n",
        ")\n",
        "\n",
        "'''\n",
        "1 - rural\n",
        "2 - subarban\n",
        "3 - metropolitan\n",
        "'''\n",
        "\n",
        "# Show the updated DataFrame with the new 'city_type' column\n",
        "df_cleaned.select('city_pop', 'city_type').show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaTnF-wEqq8M",
        "outputId": "2b5e149e-f355-4629-f999-6afb396dd122"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+\n",
            "|city_pop|city_type|\n",
            "+--------+---------+\n",
            "|3495    |rural    |\n",
            "|149     |rural    |\n",
            "|4154    |rural    |\n",
            "|1939    |rural    |\n",
            "|99      |rural    |\n",
            "|2158    |rural    |\n",
            "|2691    |rural    |\n",
            "|6018    |rural    |\n",
            "|1472    |rural    |\n",
            "|151785  |rural    |\n",
            "|7297    |rural    |\n",
            "|1925    |rural    |\n",
            "|341043  |rural    |\n",
            "|589     |rural    |\n",
            "|899     |rural    |\n",
            "|4664    |rural    |\n",
            "|1078    |rural    |\n",
            "|4081    |rural    |\n",
            "|2518    |rural    |\n",
            "|124967  |rural    |\n",
            "+--------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop specified columns from df_cleaned\n",
        "df_cleaned = df_cleaned.drop('city_pop')\n",
        "\n",
        "# Show the cleaned DataFrame to verify the columns have been removed\n",
        "df_cleaned.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNn3rmphsmx8",
        "outputId": "85ce8de0-ac2e-4824-e465-049262c9f5c4"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------+------+--------+----------------------+----+-----------+---+---------+\n",
            "|category     |amt   |gender|is_fraud|distance_from_merchant|year|Trans_month|age|city_type|\n",
            "+-------------+------+------+--------+----------------------+----+-----------+---+---------+\n",
            "|misc_net     |4.97  |F     |0       |78.59756848823062     |2019|1          |36 |rural    |\n",
            "|grocery_pos  |107.23|F     |0       |30.212175719210443    |2019|1          |46 |rural    |\n",
            "|entertainment|220.11|M     |0       |108.20608258720067    |2019|1          |62 |rural    |\n",
            "|gas_transport|45.0  |M     |0       |95.67323113819748     |2019|1          |57 |rural    |\n",
            "|misc_pos     |41.96 |M     |0       |77.5567436258178      |2019|1          |38 |rural    |\n",
            "|gas_transport|94.63 |F     |0       |85.92264266264023     |2019|1          |63 |rural    |\n",
            "|grocery_net  |44.54 |F     |0       |118.11977555909641    |2019|1          |31 |rural    |\n",
            "|gas_transport|71.65 |M     |0       |12.766922541959126    |2019|1          |77 |rural    |\n",
            "|misc_pos     |4.27  |F     |0       |25.27049367104955     |2019|1          |83 |rural    |\n",
            "|grocery_pos  |198.39|F     |0       |74.07775048182131     |2019|1          |50 |rural    |\n",
            "|grocery_pos  |24.74 |M     |0       |97.68326577207269     |2019|1          |34 |rural    |\n",
            "|shopping_net |7.77  |F     |0       |106.4293808943283     |2019|1          |58 |rural    |\n",
            "|grocery_pos  |71.22 |M     |0       |44.56107983071174     |2019|1          |35 |rural    |\n",
            "|grocery_pos  |96.29 |M     |0       |25.059079169313318    |2019|1          |79 |rural    |\n",
            "|shopping_pos |7.77  |M     |0       |66.02168481006179     |2019|1          |57 |rural    |\n",
            "|shopping_net |3.26  |M     |0       |97.93065268602581     |2019|1          |59 |rural    |\n",
            "|misc_net     |327.0 |F     |0       |87.34874840731703     |2019|1          |72 |rural    |\n",
            "|shopping_pos |341.67|M     |0       |87.99895015911639     |2019|1          |86 |rural    |\n",
            "|food_dining  |63.07 |M     |0       |90.96220878947973     |2019|1          |78 |rural    |\n",
            "|grocery_pos  |44.71 |M     |0       |84.70212030854243     |2019|1          |44 |rural    |\n",
            "+-------------+------+------+--------+----------------------+----+-----------+---+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Convert 'amt' and 'distance_from_merchant' to integer (whole numbers)\n",
        "df_cleaned = df_cleaned.withColumn('amt', col('amt').cast('int'))\n",
        "df_cleaned = df_cleaned.withColumn('distance_from_merchant', col('distance_from_merchant').cast('int'))\n",
        "\n",
        "# Show the updated DataFrame with the converted columns\n",
        "df_cleaned.select('amt', 'distance_from_merchant').show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2sSdZPjs7SG",
        "outputId": "2ca04e6f-593d-49d8-ad3b-9fb4aa6bd91f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------------+\n",
            "|amt|distance_from_merchant|\n",
            "+---+----------------------+\n",
            "|4  |78                    |\n",
            "|107|30                    |\n",
            "|220|108                   |\n",
            "|45 |95                    |\n",
            "|41 |77                    |\n",
            "|94 |85                    |\n",
            "|44 |118                   |\n",
            "|71 |12                    |\n",
            "|4  |25                    |\n",
            "|198|74                    |\n",
            "|24 |97                    |\n",
            "|7  |106                   |\n",
            "|71 |44                    |\n",
            "|96 |25                    |\n",
            "|7  |66                    |\n",
            "|3  |97                    |\n",
            "|327|87                    |\n",
            "|341|87                    |\n",
            "|63 |90                    |\n",
            "|44 |84                    |\n",
            "+---+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the cleaned DataFrame to verify the columns have been removed\n",
        "df_cleaned.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrI8GVtEtKF3",
        "outputId": "19497d39-9089-466c-d536-81f0a25af901"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---+------+--------+----------------------+----+-----------+---+---------+\n",
            "|category     |amt|gender|is_fraud|distance_from_merchant|year|Trans_month|age|city_type|\n",
            "+-------------+---+------+--------+----------------------+----+-----------+---+---------+\n",
            "|misc_net     |4  |F     |0       |78                    |2019|1          |36 |rural    |\n",
            "|grocery_pos  |107|F     |0       |30                    |2019|1          |46 |rural    |\n",
            "|entertainment|220|M     |0       |108                   |2019|1          |62 |rural    |\n",
            "|gas_transport|45 |M     |0       |95                    |2019|1          |57 |rural    |\n",
            "|misc_pos     |41 |M     |0       |77                    |2019|1          |38 |rural    |\n",
            "|gas_transport|94 |F     |0       |85                    |2019|1          |63 |rural    |\n",
            "|grocery_net  |44 |F     |0       |118                   |2019|1          |31 |rural    |\n",
            "|gas_transport|71 |M     |0       |12                    |2019|1          |77 |rural    |\n",
            "|misc_pos     |4  |F     |0       |25                    |2019|1          |83 |rural    |\n",
            "|grocery_pos  |198|F     |0       |74                    |2019|1          |50 |rural    |\n",
            "|grocery_pos  |24 |M     |0       |97                    |2019|1          |34 |rural    |\n",
            "|shopping_net |7  |F     |0       |106                   |2019|1          |58 |rural    |\n",
            "|grocery_pos  |71 |M     |0       |44                    |2019|1          |35 |rural    |\n",
            "|grocery_pos  |96 |M     |0       |25                    |2019|1          |79 |rural    |\n",
            "|shopping_pos |7  |M     |0       |66                    |2019|1          |57 |rural    |\n",
            "|shopping_net |3  |M     |0       |97                    |2019|1          |59 |rural    |\n",
            "|misc_net     |327|F     |0       |87                    |2019|1          |72 |rural    |\n",
            "|shopping_pos |341|M     |0       |87                    |2019|1          |86 |rural    |\n",
            "|food_dining  |63 |M     |0       |90                    |2019|1          |78 |rural    |\n",
            "|grocery_pos  |44 |M     |0       |84                    |2019|1          |44 |rural    |\n",
            "+-------------+---+------+--------+----------------------+----+-----------+---+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Map 'M' to 1 and 'F' to 0 in the 'gender' column\n",
        "df_cleaned = df_cleaned.withColumn(\n",
        "    'gender',\n",
        "    F.when(df_cleaned['gender'] == 'M', 1)\n",
        "     .when(df_cleaned['gender'] == 'F', 0)\n",
        "     .otherwise(df_cleaned['gender'])  # Keeps other values if there are any (optional)\n",
        ")\n",
        "\n",
        "# Show the updated DataFrame with the mapped 'gender' column\n",
        "df_cleaned.select('gender').show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O1XybyrtNMW",
        "outputId": "831b1d31-17e3-4f31-f2aa-0d72cd9bb58e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|gender|\n",
            "+------+\n",
            "|0     |\n",
            "|0     |\n",
            "|1     |\n",
            "|1     |\n",
            "|1     |\n",
            "|0     |\n",
            "|0     |\n",
            "|1     |\n",
            "|0     |\n",
            "|0     |\n",
            "|1     |\n",
            "|0     |\n",
            "|1     |\n",
            "|1     |\n",
            "|1     |\n",
            "|1     |\n",
            "|0     |\n",
            "|1     |\n",
            "|1     |\n",
            "|1     |\n",
            "+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show data types of all columns\n",
        "for col_name, dtype in df_cleaned.dtypes:\n",
        "    print(f\"Column: {col_name}, Type: {dtype}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCOebtumtV8a",
        "outputId": "9c23253f-0fde-4393-c72d-05126a6e6ff4"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column: category, Type: string\n",
            "Column: amt, Type: int\n",
            "Column: gender, Type: string\n",
            "Column: is_fraud, Type: int\n",
            "Column: distance_from_merchant, Type: int\n",
            "Column: year, Type: string\n",
            "Column: Trans_month, Type: string\n",
            "Column: age, Type: int\n",
            "Column: city_type, Type: string\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StringType\n",
        "\n",
        "# Extract categorical columns (columns with string type)\n",
        "categorical_cols = [field.name for field in df_cleaned.schema.fields if isinstance(field.dataType, StringType)]\n",
        "\n",
        "# Show the categorical columns\n",
        "print(categorical_cols)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z1Il3oguueI",
        "outputId": "75f84281-217b-4d87-db3c-f281d1601604"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['category', 'gender', 'year', 'Trans_month', 'city_type']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Define the columns to be label encoded\n",
        "cols = ['year', 'Trans_month']\n",
        "\n",
        "# Create a list to hold the StringIndexer stages\n",
        "indexers = []\n",
        "\n",
        "for col_name in cols:\n",
        "    # Create a StringIndexer for each column\n",
        "    indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_index\")\n",
        "    indexers.append(indexer)\n",
        "\n",
        "# Create a pipeline to apply the transformations\n",
        "pipeline = Pipeline(stages=indexers)\n",
        "\n",
        "# Fit and transform the data to create the new indexed columns\n",
        "df_cleaned = pipeline.fit(df_cleaned).transform(df_cleaned)\n",
        "\n",
        "# Show the updated dataframe with indexed columns\n",
        "df_cleaned.select('year', 'Trans_month', 'year_index', 'Trans_month_index').show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ryikj4yvCPQ",
        "outputId": "406f3569-ea94-4a8e-d527-51ddbc52d2a3"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------+----------+-----------------+\n",
            "|year|Trans_month|year_index|Trans_month_index|\n",
            "+----+-----------+----------+-----------------+\n",
            "|2019|          1|       0.0|              5.0|\n",
            "|2019|          1|       0.0|              5.0|\n",
            "|2019|          1|       0.0|              5.0|\n",
            "|2019|          1|       0.0|              5.0|\n",
            "|2019|          1|       0.0|              5.0|\n",
            "+----+-----------+----------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the resulting DataFrame with encoded columns\n",
        "df_cleaned.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls8xdrx1vkfn",
        "outputId": "d1d83043-70f7-451b-d8df-91f50ead8a4b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---+------+--------+----------------------+----+-----------+---+---------+----------+-----------------+\n",
            "|     category|amt|gender|is_fraud|distance_from_merchant|year|Trans_month|age|city_type|year_index|Trans_month_index|\n",
            "+-------------+---+------+--------+----------------------+----+-----------+---+---------+----------+-----------------+\n",
            "|     misc_net|  4|     0|       0|                    78|2019|          1| 36|    rural|       0.0|              5.0|\n",
            "|  grocery_pos|107|     0|       0|                    30|2019|          1| 46|    rural|       0.0|              5.0|\n",
            "|entertainment|220|     1|       0|                   108|2019|          1| 62|    rural|       0.0|              5.0|\n",
            "|gas_transport| 45|     1|       0|                    95|2019|          1| 57|    rural|       0.0|              5.0|\n",
            "|     misc_pos| 41|     1|       0|                    77|2019|          1| 38|    rural|       0.0|              5.0|\n",
            "|gas_transport| 94|     0|       0|                    85|2019|          1| 63|    rural|       0.0|              5.0|\n",
            "|  grocery_net| 44|     0|       0|                   118|2019|          1| 31|    rural|       0.0|              5.0|\n",
            "|gas_transport| 71|     1|       0|                    12|2019|          1| 77|    rural|       0.0|              5.0|\n",
            "|     misc_pos|  4|     0|       0|                    25|2019|          1| 83|    rural|       0.0|              5.0|\n",
            "|  grocery_pos|198|     0|       0|                    74|2019|          1| 50|    rural|       0.0|              5.0|\n",
            "|  grocery_pos| 24|     1|       0|                    97|2019|          1| 34|    rural|       0.0|              5.0|\n",
            "| shopping_net|  7|     0|       0|                   106|2019|          1| 58|    rural|       0.0|              5.0|\n",
            "|  grocery_pos| 71|     1|       0|                    44|2019|          1| 35|    rural|       0.0|              5.0|\n",
            "|  grocery_pos| 96|     1|       0|                    25|2019|          1| 79|    rural|       0.0|              5.0|\n",
            "| shopping_pos|  7|     1|       0|                    66|2019|          1| 57|    rural|       0.0|              5.0|\n",
            "| shopping_net|  3|     1|       0|                    97|2019|          1| 59|    rural|       0.0|              5.0|\n",
            "|     misc_net|327|     0|       0|                    87|2019|          1| 72|    rural|       0.0|              5.0|\n",
            "| shopping_pos|341|     1|       0|                    87|2019|          1| 86|    rural|       0.0|              5.0|\n",
            "|  food_dining| 63|     1|       0|                    90|2019|          1| 78|    rural|       0.0|              5.0|\n",
            "|  grocery_pos| 44|     1|       0|                    84|2019|          1| 44|    rural|       0.0|              5.0|\n",
            "+-------------+---+------+--------+----------------------+----+-----------+---+---------+----------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "# Define the non-ordinal categorical columns\n",
        "non_ordinal_cols = ['category', 'gender', 'city_type']\n",
        "\n",
        "# Step 1: Create StringIndexer and OneHotEncoder for each non-ordinal column\n",
        "indexers = []\n",
        "encoders = []\n",
        "\n",
        "for col_name in non_ordinal_cols:\n",
        "    # StringIndexer: Convert each categorical column to an index\n",
        "    indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_index\")\n",
        "\n",
        "    # OneHotEncoder: Convert the indexed column to one-hot encoding\n",
        "    encoder = OneHotEncoder(inputCol=f\"{col_name}_index\", outputCol=f\"{col_name}_onehot\")\n",
        "\n",
        "    indexers.append(indexer)\n",
        "    encoders.append(encoder)\n",
        "\n",
        "# Combine both indexers and encoders into a pipeline\n",
        "pipeline = Pipeline(stages=indexers + encoders)\n",
        "\n",
        "# Fit and transform the data, apply the transformation directly to df_cleaned\n",
        "df_cleaned = pipeline.fit(df_cleaned).transform(df_cleaned)\n",
        "\n",
        "# Step 2: Convert boolean columns to integers (example for 'is_fraud')\n",
        "df_cleaned = df_cleaned.withColumn(\"is_fraud\", F.col(\"is_fraud\").cast(IntegerType()))\n",
        "\n",
        "# Show the updated dataframe with the added one-hot encoded columns\n",
        "df_cleaned.select('category', 'gender', 'city_type', 'is_fraud').show(5)\n",
        "\n",
        "# Step 3: Inspect the schema to verify that one-hot encoded columns have been added\n",
        "df_cleaned.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69lDMC0EwFhS",
        "outputId": "06ee3e2f-717b-4b36-f8cf-cd7f7576e2c0"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------+---------+--------+\n",
            "|     category|gender|city_type|is_fraud|\n",
            "+-------------+------+---------+--------+\n",
            "|     misc_net|     0|    rural|       0|\n",
            "|  grocery_pos|     0|    rural|       0|\n",
            "|entertainment|     1|    rural|       0|\n",
            "|gas_transport|     1|    rural|       0|\n",
            "|     misc_pos|     1|    rural|       0|\n",
            "+-------------+------+---------+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- category: string (nullable = true)\n",
            " |-- amt: integer (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- is_fraud: integer (nullable = true)\n",
            " |-- distance_from_merchant: integer (nullable = true)\n",
            " |-- year: string (nullable = false)\n",
            " |-- Trans_month: string (nullable = false)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- city_type: string (nullable = false)\n",
            " |-- year_index: double (nullable = false)\n",
            " |-- Trans_month_index: double (nullable = false)\n",
            " |-- category_index: double (nullable = false)\n",
            " |-- gender_index: double (nullable = false)\n",
            " |-- city_type_index: double (nullable = false)\n",
            " |-- category_onehot: vector (nullable = true)\n",
            " |-- gender_onehot: vector (nullable = true)\n",
            " |-- city_type_onehot: vector (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling\n"
      ],
      "metadata": {
        "id": "3JGmctKSZvON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Filter the fraudulent and non-fraudulent data\n",
        "fraud_data = df_cleaned.filter(F.col('is_fraud') == 1)\n",
        "non_fraud_data = df_cleaned.filter(F.col('is_fraud') == 0)\n",
        "\n",
        "# Sample 25% of both fraud and non-fraud data\n",
        "sample_fraud_data = fraud_data.sample(fraction=0.50, seed=42)\n",
        "sample_non_fraud_data = non_fraud_data.sample(fraction=0.50, seed=42)\n",
        "\n",
        "# Combine the sampled data into one DataFrame\n",
        "sampled_data = sample_fraud_data.union(sample_non_fraud_data)\n",
        "\n",
        "# Show the result\n",
        "sampled_data.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tneGDjVQZxFa",
        "outputId": "7018840e-1ef1-4756-b172-5a0d4681e29b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----+------+--------+----------------------+----+-----------+---+---------+----------+-----------------+--------------+------------+---------------+---------------+-------------+----------------+\n",
            "|     category| amt|gender|is_fraud|distance_from_merchant|year|Trans_month|age|city_type|year_index|Trans_month_index|category_index|gender_index|city_type_index|category_onehot|gender_onehot|city_type_onehot|\n",
            "+-------------+----+------+--------+----------------------+----+-----------+---+---------+----------+-----------------+--------------+------------+---------------+---------------+-------------+----------------+\n",
            "|gas_transport|   7|     1|       1|                    34|2019|          1| 36|    rural|       0.0|              5.0|           0.0|         1.0|            0.0| (13,[0],[1.0])|    (1,[],[])|   (1,[0],[1.0])|\n",
            "|gas_transport|  10|     0|       1|                    91|2019|          1| 64| subarban|       0.0|              5.0|           0.0|         0.0|            1.0| (13,[0],[1.0])|(1,[0],[1.0])|       (1,[],[])|\n",
            "|  grocery_pos| 337|     0|       1|                    94|2019|          1| 83|    rural|       0.0|              5.0|           1.0|         0.0|            0.0| (13,[1],[1.0])|(1,[0],[1.0])|   (1,[0],[1.0])|\n",
            "|     misc_net| 707|     0|       1|                    81|2019|          1| 83|    rural|       0.0|              5.0|          11.0|         0.0|            0.0|(13,[11],[1.0])|(1,[0],[1.0])|   (1,[0],[1.0])|\n",
            "| shopping_net|1092|     1|       1|                   139|2019|          1| 36|    rural|       0.0|              5.0|           5.0|         1.0|            0.0| (13,[5],[1.0])|    (1,[],[])|   (1,[0],[1.0])|\n",
            "+-------------+----+------+--------+----------------------+----+-----------+---+---------+----------+-----------------+--------------+------------+---------------+---------------+-------------+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of rows (count of records)\n",
        "num_rows = sampled_data.count()\n",
        "\n",
        "# Number of columns\n",
        "num_columns = len(sampled_data.columns)\n",
        "\n",
        "# Shape of the DataFrame\n",
        "print(f\"Shape of the sampled data: ({num_rows}, {num_columns})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtdMnP0FZ1b5",
        "outputId": "ffe87d98-9f0f-4fe5-abd7-b5c10b701373"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the sampled data: (648804, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Step 1: Convert year and Trans_month to numeric values (IntegerType or DoubleType)\n",
        "sampled_data = sampled_data.withColumn(\"year\", sampled_data[\"year\"].cast(\"integer\"))\n",
        "sampled_data = sampled_data.withColumn(\"Trans_month\", sampled_data[\"Trans_month\"].cast(\"integer\"))\n",
        "\n",
        "# Step 2: Apply StringIndexer to categorical columns\n",
        "categorical_cols = ['category', 'gender', 'city_type']\n",
        "\n",
        "# Apply StringIndexer to convert categorical columns to numeric indices\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_index\") for col in categorical_cols]\n",
        "\n",
        "# Step 3: Assemble the features into a single vector (including the indexed columns and numeric columns)\n",
        "feature_columns = [f\"{col}_index\" for col in categorical_cols] + ['year', 'Trans_month', 'distance_from_merchant', 'age']\n",
        "\n",
        "# Apply VectorAssembler to combine all features\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "\n",
        "# Step 4: Apply StandardScaler to scale the features\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
        "\n",
        "# Step 5: Create a pipeline\n",
        "pipeline = Pipeline(stages=indexers + [assembler, scaler])\n",
        "\n",
        "# Step 6: Fit and transform the data to add scaled features\n",
        "df_transformed = pipeline.fit(sampled_data).transform(sampled_data)\n",
        "\n",
        "# Step 7: Show the transformed data with scaled features\n",
        "df_transformed.select('scaled_features', 'is_fraud').show(5)\n",
        "\n",
        "# Step 8: Split the data into training and test sets\n",
        "train_data, test_data = df_transformed.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Step 9: Show the training and test sets' shapes (row counts)\n",
        "print(f\"Training set size: {train_data.count()}\")\n",
        "print(f\"Test set size: {test_data.count()}\")\n",
        "\n",
        "# Step 10: Select features and target for model training\n",
        "train_data = train_data.select('scaled_features', 'is_fraud')\n",
        "test_data = test_data.select('scaled_features', 'is_fraud')\n",
        "\n",
        "# Show the final training data\n",
        "train_data.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "fPR6ea0kaCde",
        "outputId": "4d718eaa-a40a-49b2-e0fc-ef591b968e94"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IllegalArgumentException",
          "evalue": "requirement failed: Output column category_index already exists.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-7270763ec98c>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Step 6: Fit and transform the data to add scaled features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mdf_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Step 7: Show the transformed data with scaled features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Output column category_index already exists."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the schema to see data types\n",
        "sampled_data.printSchema()\n",
        "\n",
        "# Check a sample of the data to identify potential issues with any column\n",
        "sampled_data.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaQyKcXuanYg",
        "outputId": "9d9a0e51-6714-4924-9b2a-1dae0eed96ab"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- category: string (nullable = true)\n",
            " |-- amt: integer (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- is_fraud: integer (nullable = true)\n",
            " |-- distance_from_merchant: integer (nullable = true)\n",
            " |-- year: string (nullable = false)\n",
            " |-- Trans_month: string (nullable = false)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- city_type: string (nullable = false)\n",
            " |-- year_index: double (nullable = false)\n",
            " |-- Trans_month_index: double (nullable = false)\n",
            " |-- category_index: double (nullable = false)\n",
            " |-- gender_index: double (nullable = false)\n",
            " |-- city_type_index: double (nullable = false)\n",
            " |-- category_onehot: vector (nullable = true)\n",
            " |-- gender_onehot: vector (nullable = true)\n",
            " |-- city_type_onehot: vector (nullable = true)\n",
            "\n",
            "+-------------+----+------+--------+----------------------+----+-----------+---+---------+----------+-----------------+--------------+------------+---------------+---------------+-------------+----------------+\n",
            "|     category| amt|gender|is_fraud|distance_from_merchant|year|Trans_month|age|city_type|year_index|Trans_month_index|category_index|gender_index|city_type_index|category_onehot|gender_onehot|city_type_onehot|\n",
            "+-------------+----+------+--------+----------------------+----+-----------+---+---------+----------+-----------------+--------------+------------+---------------+---------------+-------------+----------------+\n",
            "|gas_transport|   7|     1|       1|                    34|2019|          1| 36|    rural|       0.0|              5.0|           0.0|         1.0|            0.0| (13,[0],[1.0])|    (1,[],[])|   (1,[0],[1.0])|\n",
            "|gas_transport|  10|     0|       1|                    91|2019|          1| 64| subarban|       0.0|              5.0|           0.0|         0.0|            1.0| (13,[0],[1.0])|(1,[0],[1.0])|       (1,[],[])|\n",
            "|  grocery_pos| 337|     0|       1|                    94|2019|          1| 83|    rural|       0.0|              5.0|           1.0|         0.0|            0.0| (13,[1],[1.0])|(1,[0],[1.0])|   (1,[0],[1.0])|\n",
            "|     misc_net| 707|     0|       1|                    81|2019|          1| 83|    rural|       0.0|              5.0|          11.0|         0.0|            0.0|(13,[11],[1.0])|(1,[0],[1.0])|   (1,[0],[1.0])|\n",
            "| shopping_net|1092|     1|       1|                   139|2019|          1| 36|    rural|       0.0|              5.0|           5.0|         1.0|            0.0| (13,[5],[1.0])|    (1,[],[])|   (1,[0],[1.0])|\n",
            "+-------------+----+------+--------+----------------------+----+-----------+---+---------+----------+-----------------+--------------+------------+---------------+---------------+-------------+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YGWuEYy0bVwy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}